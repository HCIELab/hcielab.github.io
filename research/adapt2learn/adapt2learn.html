<!DOCTYPE html>
<html>
<head>
	<title>Adapt2Learn: A Toolkit for Configuring the Learning Algorithm for Adaptive Physical Tools for Motor-Skill Learning</title>
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

	<!-- CSAIL ICON -->
	<link rel="CSAIL" href="http://hcie.csail.mit.edu/images/icon/csail.ico" type="image/x-icon" />

	<!-- Bootstrap -->
	<link href="https://hcie.csail.mit.edu/css/bootstrap.css" rel="stylesheet">
	<link href="https://hcie.csail.mit.edu/css/custom-style.css" rel="stylesheet">
	<!-- Lightbox -->
	<link href="../../css/lightbox.css" rel="stylesheet">


	<!-- jQuery -->
	<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>

	<!-- Google Fonts -->
	<link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Abel" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Barlow" rel="stylesheet">

	<!-- Google Analytic -->
	<script type="text/javascript" src="https://hcie.csail.mit.edu/js/analytics.js"></script>
</head>

<body>
<header class="main_header">
	<!-- to be filled by javascript, see header.html -->
</header>
<div class="container" style="padding-top: 100px;">
	<div class="row">
	<!-- Publication details -->
	<div class="col-md-4" style="text-align: left;">
		</br>
		</br>
		<span class="medium-headline">
		Publication
		</span>
		</br>
		</br>
		 <a href="https://dishitaturakhia.com">Dishita Turakhia</a>, Andrew Wong, Yini Qi, Lotta-Gili Blumberg, Yoonji Kim, Stefanie Mueller.
		</br>
		 Adapt2Learn: A Toolkit for Configuring the Learning Algorithm for Adaptive Physical Tools for Motor-Skill Learning
		</br>
		In Proceedings of
		<a href="https://dis.acm.org/2021/" target="_blank">Designing Interactive Systems &#8217;21</a>.<br>
			</br>
				<a href="https://doi.org/10.1145/3461778.3462128" class="btn btn-doi" alt="doi" target="_blank">DOI</a>
				&nbsp; &nbsp;
				<!-- TODO -->
				<a href="https://www.dropbox.com/s/0m4vavzot6198rd/DIS_21_Adapt2Learn.pdf?dl=0 " class="btn btn-pdf" alt="pdf" target="_blank">PDF</a>
				&nbsp; &nbsp;
				<a href="https://www.dropbox.com/s/s4m02vkjzhnf3ph/DIS-Final-compressed.mp4?dl=0" class="btn btn-vdo" alt="video" target="_blank">Video</a>
				&nbsp; &nbsp;
				<!-- <a href="https://www.youtube.com/watch?v=YHeSYS2eB2M" class="btn btn-vdo" alt="video" target="_blank">Talk</a>
				&nbsp; &nbsp;
				<a href="https://hcie.csail.mit.edu/research/adaptivelearning/adaptivelearning.html" class="btn btn-talk" alt="slide" target="_blank">Slides</a>
				&nbsp; &nbsp; -->
				<!-- TODO -->	
			</br>
			</br>

			<span class="medium-headline">
			Video
			</span>
			</br>
			</br>
			<!-- <iframe width="360" height="203" src="https://www.youtube.com/embed/iiMgV_dD2jo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> -->
			
			<!-- TODO -->
			<!-- <iframe width="360" height="203" src="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
			<iframe width="325" height="190" src="https://www.youtube.com/embed/T-22KOGFLoQ" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen></iframe>
			</br> -->
			</br>

			<!-- TODO -->
			<!-- <span class="medium-headline">
			Press
			</span>	
			</br>
			</br>
			<ul>
				<li><a href="https://news.mit.edu/2020/better-learning-shape-shifting-objects-1207">MIT News</a></li>
				<li><a href="https://www.digitaltrends.com/news/mit-robot-basketball-hoop/">Digital Trends</a></li>
				<li><a href="https://technews.acm.org/">ACM News</a></li>
				<li><a href="https://www.innovationtoronto.com/2020/12/shape-shifting-adaptive-training-tools-could-transform-skills-training-and-sports-training/">Innovation Toronto</a></li>
				<li><a href="https://www.sciencewiki.com/articles/better-learning-with-shape-shifting-objects-mit-researchers-have">Science Wiki</a></li>
				<li><a href="https://techxplore.com/news/2020-12-shape-shifting.html">TechXplore</a></li>
				<li><a href="https://interestingengineering.com/mit-develops-shape-shifting-basketball-hoop-for-better-training">Interesting Engineering</a></li>
				<li><a href="https://newatlas.com/good-thinking/adaptive-basketball-hoop-smaller-higher/">News Atlas</a></li>
				<li><a href="https://northernterritoryonlinenews.com.au/better-learning-with-shape-shifting-objects-tech-xplore/">Northern Territory Technology News (Australia)</a></li>
				<li><a href="https://news8plus.com/better-learning-with-shape-shifting-objects/">News8Plus</a></li>

			</ul>
			</br> -->
			<!-- TODO -->

			<!-- TODO -->
			<!-- <span class="medium-headline">
			DIS Talk Video
			</span>
			</br>
			</br>
			<iframe width="360" height="203" src="https://www.youtube.com/embed/YHeSYS2eB2M" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
			</br>
			</br> -->
			<!-- TODO -->


			<!-- TODO -->
			<!-- <span class="medium-headline">
			Slides
			</span>
			</br>
			</br> -->
			<!-- TODO -->


			<!-- TODO -->
			<!-- <img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide01.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(1)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide02.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(2)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide03.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(3)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide04.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(4)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide05.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(5)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide06.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(6)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide07.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(7)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide08.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(8)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide09.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(9)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide10.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(10)" class="hover-shadow"/>

			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide11.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(11)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide12.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(12)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide13.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(13)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide14.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(14)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide15.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(15)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide16.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(16)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide17.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(17)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide18.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(18)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide19.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(19)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide20.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(20)" class="hover-shadow"/>

			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide21.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(21)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide22.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(22)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide23.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(23)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide24.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(24)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide25.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(25)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide26.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(26)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide27.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(27)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide28.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(28)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide29.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(29)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide30.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(30)" class="hover-shadow"/>

			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide31.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(31)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide32.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(32)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide33.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(33)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide34.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(34)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide35.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(35)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide36.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(36)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide37.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(37)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide38.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(38)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide39.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(39)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide40.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(40)" class="hover-shadow"/>

			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide41.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(41)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide42.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(42)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide43.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(43)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide44.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(44)" class="hover-shadow"/> -->
			
			</div>


		<!-- For slide show -->
			<!-- close button on tne right corner -->

			<div id="lightbox-modal" class="lb-modal">
				<div class="modal-content">
				
			<div class="lb-slides">
			<div class="numbertext">1 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide01.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">2 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide02.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">3 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide03.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">4 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide04.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">5 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide05.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">6 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide06.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">7 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide07.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">8 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide08.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">9 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide09.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">10 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide10.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>


			<div class="lb-slides">
			<div class="numbertext">11 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide11.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">12 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide12.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">13 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide13.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">14 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide14.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">15 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide15.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">16 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide16.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">17 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide17.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">18 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide18.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">19 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide19.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">20 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide20.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>


			<div class="lb-slides">
			<div class="numbertext">21 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide21.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">22 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide22.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">23 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide23.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">24 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide24.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">25 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide25.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">26 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide26.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">27 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide27.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">28 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide28.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">29 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide29.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">30 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide30.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>


			<div class="lb-slides">
			<div class="numbertext">31 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide31.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">32 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide32.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">33 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide33.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">34 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide34.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">35 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide35.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">36 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide36.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">37 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide37.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">38 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide38.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">39 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide39.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">40 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide40.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			
			<div class="lb-slides">
			<div class="numbertext">41 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide41.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">42 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide42.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">43 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide43.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">44 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide44.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			

					
			<!-- Next/previous controls -->

			<a class="close-button" onclick="closeModal()">&times;</a>
			<a class="prev" onclick="plusSlides(-1)">&#10094;</a>
			<a class="next" onclick="plusSlides(1)">&#10095;</a>
		</div>
	</div>





	<!-- Project information -->
	<div class="col-md-8" style="text-align: left;">
		<br>
		<h3 class="headline">
		<b>Adapt2Learn:</b> A Toolkit for Configuring the Learning Algorithm for Adaptive Physical Tools for Motor-Skill Learning
		</h3>
		<br>
		<!-- <img src="images/Mini_Vid-Intro.gif" alt="mosculpt-runner" width="240" style="padding-bottom:0px; margin-bottom:10px"/> -->
		<img src="images/fig1-intro.png" alt="mosculpt-runner" width="720" style="padding-bottom:0px; margin-bottom:10px"/>
		<br>
		<b>
		Figure 1. (a) Designers use Adapt2Learn's user interface to configure the adaptation of their adaptive training tools, such as (b) an adaptive basketball stand that adapts its hoop height and width. Adapt2Learn auto-generates the learning algorithm as a micro-controller script that can be deployed to the tool. The algorithm uses sensor values to assess a learner's performance, computes the optimal training difficulty, and varies the training difficulty by adapting the hoop height and width. (c) Adapt2Learn's built-in visualization tool lets designers visualize their tool's adaptation and evaluate the learning algorithm.
		</b>
		<br>
		<br>
		<a href="https://hcie.csail.mit.edu/research/adaptivelearning/adaptivelearning.html">Recent study</a> on motor-skill training suggests that adaptive training tools that use shape-change to adapt the training difficulty based on learners' performance can lead to higher learning gains. However, to date, no support tools exist to help designers create adaptive learning tools. Our formative study shows that developing the adaptive learning algorithm poses a particular challenge. 
		<br>
		<br>
		To address this, we built Adapt2Learn, a toolkit that auto-generates the learning algorithm for adaptive tools. Designers choose their tool's sensors and actuators, Adapt2Learn then configures the learning algorithm and generates a microcontroller script that designers can deploy on the tool. Once uploaded, the script assesses the learner's performance via the sensors, computes the training difficulty, and actuates the tool to adapt the difficulty. Adapt2Learn's visualization tool then lets designers visualize their tool's adaptation and evaluate the learning algorithm. To validate that Adapt2Learn can generate adaptation algorithms for different tools, we build several application examples that demonstrate successful deployment.

		<br>
		<br>
		<span class="medium-headline">
		Introduction
		</span>
		<br>
		<br>
		<a href="https://dl.acm.org/doi/10.1145/3430524.3440636">Recent study on motor skill training</a> suggests that training with physical tools that adapt their shape based on a learner's performance to maintain optimal task difficulty can lead to higher learning gains. Such adaptive training tools make personalized training accessible to a broader audience and expand the design space of training tools for motor skills. However, research on supporting designers in creating such adaptive training tools that adjust training difficulty is limited. 
		<br>
		<br>
		To study the challenges in creating adaptive training tools, we conducted an 8-week formative study with 32 participants in a bi-weekly studio format. The participants built adaptive training tools for various motor skills, such as skating and swimming, in teams of two (Figure 2). Each tool used actuation to vary the training difficulty so that the learner can progress from a beginner level to an expert level. Our observations and participants' feedback indicated that they struggled the most with developing a learning algorithm for their adaptive training tools. In particular, developing an algorithm that varied task difficulty through actuation to ensure training at the optimal difficulty level was challenging.   
		<br>
		<br>
		
		To determine when to adapt the study prototype in the auto-adaptive training condition, we use an adaptation algorithm that maintains the training difficulty at the optimal challenge point, at which the task is neither too difficult nor too easy for the users. Studies in motor skill learning have shown that when coaches train learners at the optimal challenge point, learners have the maximum potential learning benefit. To maintain the difficulty level at the optimal challenge point, the algorithm measures a users' performance and based on the performance over time, determines whether the tool should adapt to a more difficult setting, a less difficult setting, or remain at the current difficulty setting during the training.
		<br>
		<br>
		According to the literature in motor skill learning, an effective learning algorithm maintains the learner's training difficulty level at the optimal challenge point, i.e., when the difficulty level is neither too difficult nor too easy for the learner's skill levels. While the recent study in HCI has demonstrated how to develop such an algorithm for adaptive training tools, no system exists to support designers in configuring it for their specific adaptive training tools. 
		<br>
		<br>
		To address this challenge, we built Adapt2Learn, a toolkit that auto-generates the adaptive learning algorithm for designers' adaptive training tools for motor skill learning. Adapt2Learn has a user interface that allows designers to configure the adaptation of their tools by setting the sensors' and actuators' values. Adapt2Learn then auto-generates the adaptive learning algorithm and exports it as a microcontroller script that designers can deploy onto their tools. The script actuates the tool's shape to maintain optimal task difficulty based on the performance sensed during training. 
		<br>
		<br>
		Additionally, Adapt2Learn has a built-in visualization tool that helps designers evaluate if their training tool is adapting appropriately and maintaining the learners' training difficulty level at the optimal challenge point during training. The visualization displays a learner's performance and shows when the tool adapts to an easier or a more difficult setting. The designers can then use the insights from this visualization to further fine-tune the algorithm.
		<br>
		<br>
		
		In summary, we contribute:

		<ul>
			<li> A formative study that highlights the need to support designers in configuring a learning algorithm for their adaptive training tools for motor skills.  </li>
			
			<li>A toolkit that supports designers in configuring a learning algorithm for their adaptive training tools. The toolkit has two parts - (1) a user interface to configure sensor and actuator values and to export a microcontroller script, and (2) a visualization tool to evaluate the adaptation during training to fine-tune the algorithm. </li>

			<li>Applications to demonstrate that Adapt2Learn can create learning algorithms for a range of adaptive training tools, such as an adaptive arm-band for golf, adaptive wobbleboard, adaptive bike, and adaptive heels.  </li>
			
		</ul>
		Below, we discuss the formative study, Adapt2Learn's user interface, and the application examples.
		<br>
		<br>


		<span class="medium-headline">
		FORMATIVE STUDY
		</span>
		<br>
		<br>
		<b>Study Design</b><br>
		To study the challenges that designers face in building adaptive training tools that train learners at the optimal challenge point, we conducted a formative study. Our formative study was an 8-weeks long bi-weekly design studio as part of an undergraduate course at our institution. We had 32 participants who were in their junior or senior year at the university, and all had prior knowledge of electronics, prototyping, and programming (at least 2 years). The participants were teamed up in groups of two. 
		<br>
		<br>
		We asked the teams to design, prototype, and build an adaptive training tool for a motor skill of their choice. In the first week, the participants brainstormed 10 ideas each and then selected one idea per team to work on for the rest of the studio. Letting the teams choose the motor skill themselves allowed us to examine the design space of adaptive training tools for various motor skills and understand the most common challenges in building them.
		<br>
		<br>
		During the 8-weeks study period, we informally interacted with the teams to discuss their design concepts, prototype implementation, and the algorithm development for their adaptive tools. The teams presented their progress and discussed the challenges with us during the studio. At the end of the 8-week design studio, we conducted semi-structured interviews to gain further insights by surveying 8 volunteering participants representing 7 teams, with two participants from the same team.  
		<br>
		<br>
		<img src="images/fig2-study.png" alt="mosculpt-runner" width="720" style="padding-bottom:0px; margin-bottom:10px"/>
		<br>
		<b>
		Figure 2. Formative study: (top) The 32 participant teams built adaptive training tools for various motor skills of their choice. While the teams successfully prototyped the adaptive training tools, study observations showed they struggled the most with developing a learning algorithm for their adaptive training tools. (bottom) List of the sensors, actuators, and their corresponding adaptation used in the adaptive training tools.
		</b>
		<br>
		<br>
		<b>Challenges Identified</b><br>
		We found that the designers faced challenges in three areas - choosing the sensors and actuators, prototyping the hardware, and configuring the learning algorithm for their adaptive training tools. The first challenge can be addressed by using the 4 guiding questions outlined in the design concept section. For the second challenge, several support tools already exist that help designers integrate their mechanisms into their tools, as listed in the related work. However, there is no support for designers to configure a learning algorithm that maintains the optimal challenge point during training. In particular, the designers faced two challenges concerning the learning algorithm:
		<br>
		<ul>
			<li> configuring a learning algorithm for their respective adaptive training tool that varies the task difficulty and maintains it at the optimal challenge point</li>
			
			<li> evaluating the learning algorithm and the tool's adaptation </li>
			
		</ul>
		
		To address these challenges, we built Adapt2Learn, a toolkit that auto-generates the adaptive learning algorithm for designers' shape-changing tools for motor skill learning. To evaluate the algorithm, Adapt2Learn has a visualization tool that lets designers visualize the learner's performance and the tool's respective adaptation.
		<br>
		<br>	

		<span class="medium-headline">
		ADAPT2LEARN TOOLKIT - WALKTHROUGH
		</span>
		<br>
		<br>
		We now demonstrate how to use the Adapt2Learn user interface for configuring the learning algorithm for adaptive training tools described in the previous section. We then explain how Adapt2Learn's built-in visualization tool helps designers assess when the tool adapts and how it affects the learner's performance. As an example, we replicated the adaptive basketball from Turakhia et al. 
		<br>
		<br>
		<img src="images/fig2-study-prototype.png" alt="mosculpt-runner" width="720" style="padding-bottom:0px; margin-bottom:10px"/>
		<br>
		<b>
		Figure 3. Study Prototype: (a) Our basketball stand with adjustable hoop height (min height: 180 cm, max height: 270 cm) and hoop width (min width: 20cm, max width: 40cm) is mounted with (b) actuators, i.e. a stepper and a servo motor for adaptation, and (c) sensors, i.e. a switch and a piezo sensor to detect if the ball went through the hoop or hit the board.
		</b>
		<br>
		<br>
		<b><strong>Configuring the Learning Algorithm using Adapt2Learn's User Interface:</strong></b><br>
		To configure the learning algorithm, designers first register the sensors and then map the sensor values to success/failure states. They then repeat the process for actuators by registering the actuators and mapping the actuator values to success/failure states. Finally, they define how the performance should be evaluated by defining the evaluation unit and running average period. We next detail these steps for the example of the adaptive basketball stand.
		<br>
		<br>
		<br>
		<!-- <img src="images/Mini_Vid-Sensor-switch.gif" alt="mosculpt-runner" width="350" style="padding-bottom:0px; margin-bottom:10px"/>
		<img src="images/Mini_Vid-Sensor-piezo.gif" alt="mosculpt-runner" width="350" style="padding-bottom:0px; margin-bottom:10px"/> -->
		<img src="images/fig3-basketball-ui.png" alt="mosculpt-runner" width="750" style="padding-bottom:0px; margin-bottom:10px"/>
		<br>
		<b>
		Figure 4. Configuring the learning algorithm using Adapt2Learn's user interface by registering sensors and mapping sensor values onto success/failure states and corresponding scores.
		</b>
		<br>
		<br>
		<b><i>Step 1: Register Sensors:</i></b><br>
		We start by hitting the <i>'create new adaptive tool'</i> button and proceed to register the sensors. In the user interface, we can select among a range of different sensors, such as piezo, switch, ultrasonic, flex, accelerometer, force resistive, PIR motion, and hall sensors. For our purposes, we select the <i>'piezo'</i> sensor, label it <i>'board_sensor'</i>, and assign it pin 13 on our microcontroller (Figure 4a). We use the <i>'add another sensor'</i> button and repeat the procedure. We select the <i>'switch'</i> from the available sensors and label it as <i>'basket_sensor'</i> and assign it pin 10 on our microcontroller (Figure 4b).
		<br>
		<br>
		<b><i>Step 2: Map Sensor Values onto Success/Failure States:</i></b><br>
		Next, we configure the sensor states and the respective threshold values that define successful and unsuccessful performance. Depending on the sensors chosen, the user interface provides the respective range of sensor values. For example, for the piezo sensor, the user interface provides a range of values (0-255) whereas for the switch sensor, it provides only boolean values.
		<br>
		<br>
		<b><i>Step 3: Register Actuators:</i></b><br>
		Next, we register the actuators. In the user interface, we can select among a range of different actuators, such as a servo motor, stepper motor, pneumatic pump, and relay. Depending on the actuators chosen, the user interface provides the respective range of actuator values. For our purposes of raising and lowering the hoop height, we select <i>'stepper motor'</i> from the list of actuators and label it <i>'stand_motor'</i>. We assign it pin 1 on our microcontroller, and the user interface automatically assigns the remaining pins 2, 3, and 4 required for the stepper motor (Figure 4c).	We then add the motor that widens and tightens the hoop by clicking <i>'add another actuator'</i> button. We then select <i>'servo motor'</i> and label it <i>'hoop_motor'</i>, and then assign it pin 9 on the microcontroller (Figure 4d). 
		<br>
		<!-- <br>
		
		<img src="images/Mini_Vid-Actuator_stepper.gif" alt="mosculpt-runner" width="150" style="padding-bottom:0px; margin-bottom:10px"/>
		<img src="images/Mini_Vid-Actuator_servo.gif" alt="mosculpt-runner" width="150" style="padding-bottom:0px; margin-bottom:10px"/>
		<img src="images/fig3-basketball-ui.png" alt="mosculpt-runner" width="750" style="padding-bottom:0px; margin-bottom:10px"/>

		<br> -->
		<!-- <b>
		Figure 5. Configuring the learning algorithm using Adapt2Learn's user interface by registering actuators and mapping actuator values onto success/failure states.
		</b> -->
		<!-- <br> -->
		<br>
		<b><i>Step 4: Map Actuation Values onto Success/Failure States:</i></b><br>
		Next, we map the motors' actuation values onto adaptation states. We define states for the <i>'stand_motor'</i> (stepper motor): <i>'stand\_raise'</i> as <i>'success'</i> and with the motor turning 16 revolutions to increase the hoop height, and <i>'stand_lower'</i> as <i>'failure'</i> and with the motor turning -16 revolutions to decrease the hoop height (Figure 4c). We repeat the process for the hoop motor by defining <i>'hoop_motor'</i> (servo motor): <i>'hoop_tighten'</i> as <i>'success'</i> with the motor turning 8 revolutions, and <i>'hoop_widen'</i> as <i>'failure'</i> with the motor turning -8 revolutions (Figure 4d).
		<br>
		<br>
		<b><i>Step 5: Define Performance Evaluation Unit and Running Average Period:</i></b><br>
		Finally, we set up the performance evaluation unit (Figure 5a). The <i>'evaluation unit'</i> can be either <i>'attempts'</i> or <i>'time'</i>. For our adaptive basketball prototype, we select <i>'attempts'</i> representing attempted throws at the basket. Next, we define the <i>'running average period'</i>, i.e. the period over which the algorithm will evaluate the learner's performance. Depending on which evaluation unit was selected, the running average period is either a number of attempts (after 4 throws in our basketball example) or a time period (after 10 minutes in balancing a bike). We also set the time limit after which, if no sensor value is detected, the attempt is considered as a failure, for example as 10 seconds. 
		<br>
		<br>
		
		<b><strong>Generating the Microcontroller Script According to the Configuration:</strong></b><br>
		After configuring the learning algorithm using the steps described above, designers can hit the <i>'export'</i> button, which automatically generates the microcontroller code (Arduino script in .ino file format). After exporting, designers can then deploy the script onto the microcontroller integrated with their adaptive training tools.
		<br>
		<br>
		<b><strong>Visualization Tool: Displaying Performance and Adaptation:</strong></b><br>
		To provide tool designers with a way to assess the learner's performance and when the tool adapts, we added a visualization tool. The visualization tool plots the learner's attempt scores, the corresponding running average, and the computed derivative of the running average at that attempt. This performance data is plotted in real-time along with when the tool adapts to an easier or more difficult setting. 
		<br>
		<br>
		The visualization helps monitor how the configured learning algorithm takes a learner from a low difficulty setting to a high difficulty setting while maintaining their performance score at the optimal challenge point. 
		<br>
		<br>
		<img src="images/fig5-viztool.png" alt="mosculpt-runner" width="720" style="padding-bottom:0px; margin-bottom:10px"/>
		<br>
		<b>
		Figure 5. Visualization of the scoring of a learner and the adaptation frequency over a number of attempts. The visualization thus helps monitor how the configured learning algorithm takes a learner from a low difficulty setting to a high difficulty setting while maintaining their performance score at the optimal challenge point.
		</b>
		<br>
		<br>
		

		<span class="medium-headline">
		APPLICATION EXAMPLES OF ADAPTIVE LEARNING TOOLS USING ADAPT2LEARN
		</span>
		<br>
		<br>
		We built and configured an adaptive armband that supports learners in keeping their elbow straight during the golf-swing. The armband has a flex sensor to detect if the learner's elbow is straight or bent, and a pneumatic pump to deflate and inflate the arm band to restrict bending of the elbow 
		<br>
		<br>
		<b>Adaptive Armband for Golf: Single Sensor-Actuator Combination</b>
		<br>
		We built and configured an adaptive armband that supports learners in keeping their elbow straight during the golf-swing. The armband has a flex sensor to detect if the learner's elbow is straight or bent, and a pneumatic pump to deflate and inflate the arm band to restrict bending of the elbow (Figure~\ref{fig:golf}). 
		<br>
		<br>
		<img src="images/fig6-golfa.png" alt="mosculpt-runner" width="350" style="padding-bottom:0px; margin-bottom:10px"/>
		<img src="images/fig6-golfb.png" alt="mosculpt-runner" width="350" style="padding-bottom:0px; margin-bottom:10px"/>
		<br>
		<b>
		Figure 6. An adaptive armband that supports learners in keeping their elbow straight during the golf-swing, integrated with one flex sensor and  one pneumatic pump. Configuring the learning algorithm for the armband using \textit{Adapt2Learn}'s user interface.
		</b>
		<br>
		<br>
		The configured algorithm then senses the bending and inflates or deflates the armband to provide more or less support to the learner and thus varies the task difficulty. For example, if the learner bends the elbow too often during training, the algorithm makes the task difficulty easier by inflating the armband thereby restricting the bending, and thus providing more support to the learner by keeping the elbow straight.   
		<br>
		<br>

		<b>Adaptive Wobbleboard: Synchronizing Sensors:</b>
		<br>
		We built and configured an adaptive wobbleboard with inflatable cushion that supports learners in learning to balance the board. The wobbleboard has two ultrasonic sensors mounted on diametrically opposite sides of the board to detect if it is stable or wobbling, and a pneumatic pump to deflate and inflate the support cushion that restricts wobbling (Figure~\ref{fig:adapt2learnwobble}). 
		<br>
		<br>
		<img src="images/fig7a-wobbleboard.png" alt="mosculpt-runner" width="350" style="padding-bottom:0px; margin-bottom:10px"/>
		<img src="images/fig7b-wobbleboard.png" alt="mosculpt-runner" width="350" style="padding-bottom:0px; margin-bottom:10px"/>
		<br>
		<b>
		Figure 7. An adaptive wobbleboard with inflatable cushion that supports learners in learning to balance the board. Configuring the learning algorithm for the wobbleboard using \textit{Adapt2Learn}'s user interface to set synchronized two ultrasonic sensors and one pneumatic pump.
		</b>
		<br>
		<br>
		If the configured algorithm detects a failure state for either of the sensors, it implies that the corresponding edge of the wobbleboard is too high, and the other edge is too low (<5cm), meaning that the wobble board is imbalanced. Thus, two sensors can be used in tandem to detect balancing. To support the learner in keeping the wobbleboard balanced, the pneumatic pump can then inflate the cushion. Alternatively, if the learner balances the wobbleboard well, the pump deflates the cushion, thereby reducing the support and making the task of balancing harder. 
		<br>
		<br>

		<b>Adaptive Bike: Synchronizing Actuators</b>
		<br>
		We built and configured a bike with adaptive training wheels that supports learners in learning to balance the bike. The bike has one hall-effect sensor mounted on each of the training wheels to detect if the training wheel is being used, and one stepper motor on each of the training wheels to lower or raise them to provide more or less support in balancing the bike (Figure~\ref{fig:bike}). 
		<br>
		<br>
		<img src="images/fig8a-bike.png" alt="mosculpt-runner" width="350" style="padding-bottom:0px; margin-bottom:10px"/>
		<img src="images/fig8b-bike.png" alt="mosculpt-runner" width="350" style="padding-bottom:0px; margin-bottom:10px"/>
		<br>
		<b>
		Figure 8. A bike with adaptive training wheels that supports learners in learning to balance the bike. Configuring the learning algorithm for the adaptive bike using \textit{Adapt2Learn}'s user interface to set two synchronized hall-effect sensors and two synchronized stepper motors.
		</b>
		<br>
		<br>
		If the configured algorithm detects a failure state too often for either of the sensors, it implies that the learner is unable to balance without the use of the training wheels. The stepper motors then lower the wheels further to provide more support to the learner. Since both the actuators are mapped to the same failure state, they both turn at the same time and by the same amount. In this way two sensor values can be mapped to two actuator values in combination.  
		<br>
		<br>

		<b>Adaptive Heels: Synchronized Sensors and Actuators</b>
		<br>
		In addition to the above examples, we also configured the learning algorithm for the studio-built adaptive heels that support learners in training to walk in high heels (Figure \ref{fig:heels}). The participant team mounted two ultrasonic distance sensors per shoe, one on each side of the heel to measure the balance of the learner while walking in the heels. One servo motor was mounted on each of the shoe to raise and lower the heel height while walking. Thus, the adaptive heels had a combination of 4 synchronized sensors and 2 synchronized actuators. This ensures that both the heels were synchronized in their adaptation. Thus only when all the four sensor values detected success states, the servo motors actuated to raise the heels and increased the difficulty of walking. Note that the 3D printed spindle that increased and decreased its height by the servo motor at the base of the heel supported the weight of the learner while walking. 
		<br>
		<br>
		<img src="images/fig9a-heels.png" alt="mosculpt-runner" width="350" style="padding-bottom:0px; margin-bottom:10px"/>
		<img src="images/fig9b-heels.png" alt="mosculpt-runner" width="350" style="padding-bottom:0px; margin-bottom:10px"/>
		<br>
		<b>
		Figure 9. Adaptive heels that support learners in training to walk in high heels. Configuring the learning algorithm for the adaptive heels using \textit{Adapt2Learn}'s user interface to set four synchronized ultrasonic distance sensors (two per shoe), and two synchronized servo motors.
		</b>
		<br>
		<br>
		In the same way that we used our user interface to configure the examples above, the user interface can be used to configure other examples from the studio, such as the adaptive skateboard, dartboard, fencing, jumprope, and cornhole prototypes {(see Figure \ref{fig:classprojects})} that use similar sensor-actuator combinations. 
		<br>
		<br>
		However, we also encountered two challenges for which we could not yet configure the learning algorithm using our user interface. The first challenge occurs when the success state is coupled with a specific timing, such as when hitting a note on time for playing piano. For instance, the adaptive piano used a switch sensor to sense if a key was pressed at the right time and then actuated the servo motor under the key to provide feedback to the learner on which key to press next. Since our user interface does not support time-based sensing, we were not able to configure the learning algorithm for this adaptation. The second challenge occurs when additional processing on the sensor data is needed. For example, both the adaptive pitching machine and the adaptive juggling used a camera to detect the learner's position, which requires computer vision techniques that go beyond the sensor value thresholding that our user interface currently supports. 
		<br>
		<br>
		In summary, we demonstrated the use of \textit{Adapt2Learn} for configuring the learning algorithm for a variety of applications that ranged from single sensor-actuator combinations (e.g., golf-arm band) to multiple synchronized sensor-actuator combinations (e.g., adaptive heels). 

		



		<br>
		<br>
		<span class="medium-headline">
		
		DISCUSSION
		</span>
		<br>
		<br>
		We illustrated how \textit{Adapt2Learn} supports designers in configuring the learning algorithm for their custom adaptive training tools. \textit{Adapt2Learn's} built-in visualization tool then supports designers in assessing the learner's performance and the tool's adaptation. The interface also allows designers to update the learning algorithm without re-programming the microcontroller code. We next discuss the limitations of our toolkit and provide directions for future work:
		<br>
		<br>
		<b><i>Extending the Range of Supported Components:</i></b> Adapt2Learn} currently supports 8 sensors and 4 actuators, which can be used in multiple sensor-actuator combinations, as seen in our examples. However, as discussed earlier, providing more components would further extend the range of adaptive tools for configuring the learning algorithm. For the future, we plan to integrate components that require more processing, such as depth sensors and cameras. Additionally, adding time-based sensing and custom components to the user interface could be a direction for future work.
		<br>
		<br>
		<b><i>Configuring the Algorithm in Real-time:</i></b> While currently, our system provides real-time visualization of the learner's performance and tool's adaptation, it does not allow for real-time reconfiguration of the learning algorithm. The designers currently have to reconfigure the values, re-export the microcontroller script, and then deploy it again onto the adaptive tool. In future work, we plan to support designers to update the configuration of a learning algorithm in real-time in the learning situation.
		<br>
		<br>
		<b><i>Evaluating the toolkit through user studies:</i></b> While we demonstrated that \textit{Adapt2Learn} can be used for configuring various adaptive training prototypes, evaluating the use of toolkit through user studies with designers and testing it in different phases of the design process is a part of our future work. 
		<br>
		<br>
		<b><i>Visualizing the Learning Trajectory:</i></b> While not the focus of our work, the visualization tool may also help assess how long the learner takes to transition from a low difficulty level to a high difficulty level, and predict the time needed to reach the highest skill level. Additionally, the visualization tool may also allow comparing the learning trajectory of multiple learners and gain more insights into that motor skill's learning.
		<br>
		<br>
		<b><i>Comparing Different Tool Designs:</i></b> When building an adaptive training tool, designers have different options for sensing the learner's performance and adapting the task difficulty. For instance, when designing the adaptive basketball, instead of only detecting board and basket hits with a piezo sensor and switch, a camera can be used to sense the ball's trajectory, which provides more information. However, it is unclear which sensing-adapting method leads to the best results. Providing a way to compare the adaptation of different designs for the same training tool could allow designers to choose their designs appropriately.
		<br>
		<br>
		<b><i>Supporting Multiple Learners:</i></b> Many skills involve learning as a group where individuals may have varying skill levels. While currently the exported microcontroller script from our user interface and our visualization tool monitor a single learner's performance, a future direction for research could be to extend both the user interface and the visualization tool to support multiple learners at the same time.
		<br>
		<br>

		<span class="medium-headline">
		CONCLUSION
		</span>
		<br>
		<br>
		We developed a toolkit that supports designers in creating adaptive training tools that maintain the task difficulty at the optimal challenge point. Our formative study showed that designers needed support, particularly in configuring the learning algorithm and assessing the tool's adaptation. We showed that \textit{Adapt2Learn} addressed these two challenges through its user interface and its visualization tool. We showed that \textit{Adapt2Learn's} user interface supports configuring the learning algorithm by first registering the sensors and actuators of the adaptive tools, then mapping their values to success/failure states, and finally exporting the auto-generated micro-controller script, which can be deployed onto the micro-controller integrated with the tools. Furthermore, we showed how \textit{Adapt2Learn's} built-in visualization tool supports designers in assessing if the learning algorithm maintains the task difficulty at the optimal challenge point during training by visualizing the learner's performance and the tool's adaptation. We demonstrated \textit{Adapt2Learn's} use to configure the learning algorithm for five different adaptive tools with various sensor/actuator combinations, such as an adaptive basketball, armband for golf, wobbleboard, bike, and adaptive heels.  
		<br>
		<br>
		

		<span class="medium-headline">
		ACKNOWLEDGMENTS
		</span>
		<br>
		<br>
		We thank the 32 students at MIT, who took the 6.810 course and participated in the study. We thank Junyi Zhu for his help with the viztool. We also thank Or Oppenheimer and Christian De Weck for their contribution in building the prototypes. This work is supported by <a href="https://mitili.mit.edu/">MIT Learning Initiative</a> and the National Science Foundation under Grant No. 1844406.
		<br>
		<br>


		<br>
		<br>
		<br>
		<br>
		<br>
		<br>
		<br>
		<br>
		<br>
		<br>


	</div>
	</div>
</div>

<div class="container">
	<div class="row">
		<div class="col-md-12 footer" style="text-align: center;">
			<span class="copyright">
			Since 2017 &copy; MIT CSAIL (HCI Engineering group) [redesign by
			<a href="http://punpongsanon.info/" target="_blank" style="text-decoration:none; border-bottom:0px">
			moji
			</a>].
			All Rights Reserved.

			<a href="http://mit.edu/" target="_blank" style="text-decoration:none; border-bottom:0px">
			<img src="http://hcie.csail.mit.edu/images/logo/mit.svg" alt="MIT" class="footer-logo" />
			</a>
			<a href="http://csail.mit.edu/" target="_blank" style="text-decoration:none; border-bottom:0px">
			<img src="http://hcie.csail.mit.edu/images/logo/csail.svg" alt="CSAIL" class="footer-logo"/>
			</a>
			<a href="http://hci.csail.mit.edu/" target="_blank" style="text-decoration:none; border-bottom:0px">
			<img src="http://hcie.csail.mit.edu/images/logo/hci.svg" alt="HCI" class="footer-logo"/>
			</a>
			</span>
		</div>
	</div>
</div>

<!-- Bootstrap -->
<script type="text/javascript" src="https://hcie.csail.mit.edu/js/bootstrap.min.js"></script>
<!-- header -->
<script type="text/javascript" src="https://hcie.csail.mit.edu/js/headerstrap-for-subpage.js"></script>
<!-- lightbox -->
<script type="text/javascript" src="../../js/lightbox.js"></script>

</body>
</html>
