<!DOCTYPE html>
<html>
<head>
	<title>Identifying Game Mechanics for Integrating Fabrication Activities within Existing Digital Games</title>
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

	<!-- CSAIL ICON -->
	<link rel="CSAIL" href="http://hcie.csail.mit.edu/images/icon/csail.ico" type="image/x-icon" />

	<!-- Bootstrap -->
	<link href="https://hcie.csail.mit.edu/css/bootstrap.css" rel="stylesheet">
	<link href="https://hcie.csail.mit.edu/css/custom-style.css" rel="stylesheet">
	<!-- Lightbox -->
	<link href="../../css/lightbox.css" rel="stylesheet">


	<!-- jQuery -->
	<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>

	<!-- Google Fonts -->
	<link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Abel" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Barlow" rel="stylesheet">

	<!-- Google Analytic -->
	<script type="text/javascript" src="https://hcie.csail.mit.edu/js/analytics.js"></script>
</head>

<body>
<header class="main_header">
	<!-- to be filled by javascript, see header.html -->
</header>
<div class="container" style="padding-top: 100px;">
	<div class="row">
	<!-- Publication details -->
	<div class="col-md-4" style="text-align: left;">
		</br>
		</br>
		<span class="medium-headline">
		Publication
		</span>
		</br>
		</br>
		 <a href="https://dishitaturakhia.com">Dishita Turakhia</a>, Stefanie Mueller, Kayla DesPortes.
		</br>
		 Identifying Game Mechanics for Integrating Fabrication Activities within Existing Digital Games
		</br>
		In Proceedings of
		<a href="https://chi2022.acm.org/" target="_blank">Human Factors in Computing &#8217;22</a>.<br>
			</br>
				<a href="https://doi.org/10.1145/3491102.3517721" class="btn btn-doi" alt="doi" target="_blank">DOI</a>
				&nbsp; &nbsp;
				
				<a href="https://groups.csail.mit.edu/hcie/files/research-projects/fabogamemechanics/Turakhia-Integrating_game mechanics.pdf" class="btn btn-pdf" alt="pdf" target="_blank">PDF</a>
				&nbsp; &nbsp;
				<!-- TODO -->
			<!-- 	<a href="https://www.dropbox.com/s/692ur2fzihsdie4/FabO-video-final.mp4?dl=0" class="btn btn-vdo" alt="video" target="_blank">Video</a>
				&nbsp; &nbsp;
				<a href="https://youtu.be/ybfgJFN7EdU" class="btn btn-vdo" alt="video" target="_blank">Talk</a>
				&nbsp; &nbsp; -->
				<!-- <a href="https://hcie.csail.mit.edu/research/adaptivelearning/adaptivelearning.html" class="btn btn-talk" alt="slide" target="_blank">Slides</a>
				&nbsp; &nbsp; -->
				<!-- TODO -->	
			</br>
			</br>

			<!-- <span class="medium-headline">
			Video
			</span>
			</br>
			</br> -->
			<!-- <iframe width="360" height="203" src="https://www.youtube.com/embed/iiMgV_dD2jo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> -->
			
			<!-- TODO -->
			<!-- <iframe width="360" height="203" src="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
			<iframe width="325" height="190" src="https://www.youtube.com/embed/T-22KOGFLoQ" frameborder="0" gesture="media" allow="encrypted-media" allowfullscreen></iframe>
			</br> -->
			</br>

			<!-- TODO -->
			<!-- <span class="medium-headline">
			Press
			</span>	
			</br>
			</br>
			<ul>
				<li><a href="https://news.mit.edu/2020/better-learning-shape-shifting-objects-1207">MIT News</a></li>
				<li><a href="https://www.digitaltrends.com/news/mit-robot-basketball-hoop/">Digital Trends</a></li>
				<li><a href="https://technews.acm.org/">ACM News</a></li>
				<li><a href="https://www.innovationtoronto.com/2020/12/shape-shifting-adaptive-training-tools-could-transform-skills-training-and-sports-training/">Innovation Toronto</a></li>
				<li><a href="https://www.sciencewiki.com/articles/better-learning-with-shape-shifting-objects-mit-researchers-have">Science Wiki</a></li>
				<li><a href="https://techxplore.com/news/2020-12-shape-shifting.html">TechXplore</a></li>
				<li><a href="https://interestingengineering.com/mit-develops-shape-shifting-basketball-hoop-for-better-training">Interesting Engineering</a></li>
				<li><a href="https://newatlas.com/good-thinking/adaptive-basketball-hoop-smaller-higher/">News Atlas</a></li>
				<li><a href="https://northernterritoryonlinenews.com.au/better-learning-with-shape-shifting-objects-tech-xplore/">Northern Territory Technology News (Australia)</a></li>
				<li><a href="https://news8plus.com/better-learning-with-shape-shifting-objects/">News8Plus</a></li>

			</ul>
			</br> -->
			<!-- TODO -->

			<!-- TODO -->
			<span class="medium-headline">
			CHI'22 Talk Video
			</span>
			</br>
			</br>
			<!-- <iframe width="360" height="203" src="https://www.youtube.com/embed/ybfgJFN7EdU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> -->
			</br>
			</br>
			<!-- TODO -->


			<!-- TODO -->
			<!-- <span class="medium-headline">
			Slides
			</span>
			</br>
			</br> -->
			<!-- TODO -->


			<!-- TODO -->
			<!-- <img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide01.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(1)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide02.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(2)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide03.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(3)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide04.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(4)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide05.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(5)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide06.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(6)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide07.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(7)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide08.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(8)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide09.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(9)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide10.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(10)" class="hover-shadow"/>

			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide11.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(11)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide12.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(12)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide13.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(13)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide14.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(14)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide15.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(15)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide16.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(16)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide17.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(17)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide18.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(18)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide19.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(19)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide20.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(20)" class="hover-shadow"/>

			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide21.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(21)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide22.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(22)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide23.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(23)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide24.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(24)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide25.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(25)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide26.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(26)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide27.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(27)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide28.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(28)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide29.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(29)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide30.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(30)" class="hover-shadow"/>

			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide31.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(31)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide32.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(32)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide33.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(33)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide34.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(34)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide35.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(35)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide36.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(36)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide37.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(37)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide38.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(38)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide39.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(39)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide40.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(40)" class="hover-shadow"/>

			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide41.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(41)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide42.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(42)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide43.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(43)" class="hover-shadow"/>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide44.jpg" width="100px" style="padding-bottom:0px; margin-bottom:10px" onclick="openModal();currentSlide(44)" class="hover-shadow"/> -->
			
			</div>


		<!-- For slide show -->
			<!-- close button on tne right corner -->

			<div id="lightbox-modal" class="lb-modal">
				<div class="modal-content">
				
			<div class="lb-slides">
			<div class="numbertext">1 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide01.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">2 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide02.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">3 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide03.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">4 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide04.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">5 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide05.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">6 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide06.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">7 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide07.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">8 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide08.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">9 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide09.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">10 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide10.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>


			<div class="lb-slides">
			<div class="numbertext">11 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide11.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">12 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide12.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">13 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide13.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">14 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide14.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">15 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide15.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">16 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide16.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">17 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide17.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">18 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide18.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">19 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide19.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">20 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide20.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>


			<div class="lb-slides">
			<div class="numbertext">21 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide21.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">22 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide22.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">23 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide23.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">24 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide24.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">25 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide25.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">26 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide26.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">27 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide27.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">28 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide28.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">29 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide29.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">30 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide30.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>


			<div class="lb-slides">
			<div class="numbertext">31 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide31.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">32 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide32.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">33 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide33.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">34 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide34.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">35 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide35.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">36 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide36.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">37 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide37.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">38 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide38.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">39 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide39.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			<div class="lb-slides">
			<div class="numbertext">40 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide40.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			
			<div class="lb-slides">
			<div class="numbertext">41 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide41.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">42 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide42.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">43 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide43.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>

			<div class="lb-slides">
			<div class="numbertext">44 / 44</div>
			<img src="http://groups.csail.mit.edu/hcie/files/research-projects/adaptive-physical-tools/TEI-Talk-Slides/Slide44.jpg" style="padding-bottom:0px; margin-bottom:10px; width:100%">
			</div>
			
			

					
			<!-- Next/previous controls -->

			<a class="close-button" onclick="closeModal()">&times;</a>
			<a class="prev" onclick="plusSlides(-1)">&#10094;</a>
			<a class="next" onclick="plusSlides(1)">&#10095;</a>
		</div>
	</div>





	<!-- Project information -->
	<div class="col-md-8" style="text-align: left;">
		<br>
		<h3 class="headline">
		Identifying Game Mechanics for Integrating Fabrication Activities within Existing Digital Games
		</h3>
		<br>
		<!-- <img src="images/Mini_Vid-Intro.gif" alt="mosculpt-runner" width="240" style="padding-bottom:0px; margin-bottom:10px"/> -->
		<img src="images/Fig1-Intro.PNG" alt="mosculpt-runner" width="750" style="padding-bottom:0px; margin-bottom:10px"/>
		<br>
		<b>
		Figure 1. To help designers integrate fabrication activities within existing games, we use the Mechanics-Dynamics-Aesthetics (MDA) framework and modify it to f-MDA to identify the game mechanics that allow meaningful integration. For example, in the game of <i>Animal Crossing</i>, the game mechanics that allows designing custom clothing can be used to allow the players to physically fabricate their designs and create objects that are associated with their creativity and self-expression.
		</b>
		<br>
		<br>
		Integrating fabrication activities into existing video games provides opportunities for players to construct objects from their gameplay and bring the digital content into the physical world. In our prior work, we outlined a framework and developed a toolkit for integrating fabrication activities within existing digital games. Insights from our prior study highlighted the challenge of aligning fabrication mechanics with the existing game mechanics in order to strengthen the player aesthetics. 
		<br>
		<br>
		In this paper, we address this challenge and build on our prior work by adding fabrication components to the Mechanics-Dynamics-Aesthetics (MDA) framework. We use this f-MDA framework to analyze the 47 fabrication events from the prior study. We list the new player-object aesthetics that emerge from integrating the existing game mechanics with fabrication mechanics. We identify connections between these emergent player-object aesthetics and the existing game mechanics. We discuss how designers can use this mapping to identify potential game mechanics for integrating with fabrication activities.  
		<br>
		<br>
		<span class="medium-headline">
		INTRODUCTION
		</span>
		<br>
		<br>
		Fabrication games that combine fabrication activities with a player's gameplay are an emerging area of research in HCI for their potential to augment the gaming experience in several ways. Objects fabricated from the fabrication games can introduce novel interactions in the gameplay (for example, by fabricating customized game-controllers), teach fabrication skills through gameplay, and increase player motivation by bringing the digital content into the physical world. To integrate fabrication activities as part of the gameplay, these fabrication games are typically designed from scratch, which can be a time-consuming process and may require an expertise in game design. 
		<br>
		<br>
		Instead of building games from scratch, in our prior work~\cite{2021fabo}, we presented a framework for modifying \textit{existing} digital games into fabrication games, by using computer vision to integrate fabrication activities within gameplay moments. We implemented this framework as a toolkit that allows game designers to tag the onscreen visual content of existing game mechanics and integrate it with fabrication mechanics to strengthen the player experience---i.e. the aesthetics using fabrication. Results from the user studies validated the workflow and its potential to augment a myriad of existing games into fabrication games. In particular, understanding the impact of the designer's choice gameplay moments and its integration with fabrication mechanics on the player's experience was unexplored.  
		<br>
		<br>
		In this paper, we use the prior study results~\cite{2021fabo} and further analyze them with the goal of understanding the player experiences emerging from the integration of existing game mechanics~\cite{sicart2008defining} and fabrication activities. We first analyze the 47 fabrication events designed by the study participants from the prior study as this study data provides a wide range of example points for the analysis. To analyze these events through its design and technical components, we use the widely cited Mechanics-Dynamics-Aesthetics (MDA) framework~\cite{hunicke2004mda}. For the analysis, we first modify the MDA framework to f-MDA and incorporate the fabrication components that result from the integration of fabrication activities. We examine each of the 47 events using f-MDA, and identify its corresponding game mechanics, system dynamics, player aesthetics, fabrication mechanics, process of fabrication, and object use.  
		<br>
		<br>
		We found that fabricated objects have the potential to enhance and expand the existing game mechanics in new ways. We noted that the integration led to the emergence of new player-object aesthetics in most cases. We define player-object aesthetics as the emotional associations that the players develop with the objects fabricated from their personal gameplay. For example, a player fabricating a trophy from their winning gameplay could associate it as an object of pride. Our analysis shows the emergence of a set of five new player-object aesthetics (namely, objects of pride, creativity, resource, function, and shared memory) resulting from the fabrication of objects. We map the links between these emergent player-object aesthetics and the existing game mechanics. Designers can use this bidirectional mapping to identify the potential of existing game mechanics to lead to player-object aesthetics and vice versa, and thus integrate fabrication activities with existing digital games. 
		<br>
		<br>
		
		In summary, we contribute the following:

		<ul>
			<li>We analyze 47 fabrication events using a modified Mechanics-Dynamics-Aesthetics framework (f-MDA) to evaluate how fabrication mechanics can strengthen player aesthetics and introduce new aesthetics.  </li>
			
			<li>We list a set of five player-object aesthetics that emerge out of integration of fabrication mechanics and existing game mechanics. Although non-exhaustive, the list is indicative of opportunities to use fabrication to introduce new player experiences within existing games. </li>

			<li>We provide a bidirectional mapping to link the emergent player-aesthetics with existing game mechanics, that can help to identify the appropriate game mechanics for integrating fabrication activities with existing games.  </li>
			
		</ul>
		
		<br>


		<span class="medium-headline">
		Prior Study
		</span>
		<br>
		<br>
		This paper builds on our prior study~\cite{2021fabo} that evaluated the workflow and the usability of our toolkit for integrating fabrication activities within the gameplay of existing digital games. While our earlier work provided insights on the usability of the toolkit, in this paper we examine and analyze the study results further from the game design perspective through the lens of the f-MDA framework.   
		<br>
		<br>
		Within the scope of our study, we use the term \textit{``designers"} to refer to the participants who modified existing games into fabrication games using our toolkit, and use the term \textit{``players"} to refer to the users who would play the modified fabrication games using our toolkit.  
		<br>
		<br>
		<b>The Toolkit Workflow:</b><br>
		The toolkit allowed \textit{designers} to tag on-screen visual content (i.e. text or images) from existing games to mark gameplay moments that trigger fabrication events in the gameplay. When players of the fabrication games encounter these respective fabrication events during their gameplay, they can choose to fabricate the objects using our toolkit. Figure ~\ref{toolkit} illustrates the toolkit's workflow that takes existing games as input and then outputs the fabrication files of the objects from the game. 
		<br>
		<br>
		As an illustrative example, consider the fabrication event in the game of MarioKart, where the players can fabricate a collectible of the character, Rosalina as soon as the character gets unlocked. To integrate this fabrication event, designers would first use our toolkit's designer interface to choose the gameplay moment and capture its screenshot from videos of recorded gameplay available on video platforms, such as Youtube, or play the game themselves. Using the features of the designer interface, they would then tag the on-screen visual content as cues to identify the gameplay moment. For example, when Rosalina is unlocked in the game, designers could tag the on-screen visual cues, such as text (for example, `Congratulations! You have unlocked Rosalina'  as seen in Figure \ref{toolkit}-2b) or images (for example, the image of Rosalina's character) associated with that gameplay moment. Next, the designers can tag the on-screen regions to select the game objects for fabrication, for example, the region where Rosalina appears (Figure \ref{toolkit}-2c) and generate the event. These tagged visual cues allow our system to locate this gameplay moment using computer vision, during the players' live play. Once designers are done tagging cues they can then export all the fabrication events in a single file (JSON format). 
		<br>
		<br>
		<img src="images/fig2-framework.png" alt="mosculpt-runner" width="750" style="padding-bottom:0px; margin-bottom:10px"/>
		<br>
		<b>
		Figure 2. FabO's framework uses on-screen visual content to (1) allow designers to integrate fabrication with existing games and (2) auto-generate the fabrication files to allow players to fabricate objects from their gameplay.
		</b>
		<br>
		<br>
		Players can then load this events file in our player interface, use the interface to monitor their screen, and then start playing the game as they normally would. Our system monitors their gameplay using computer vision, scans for tagged cues, and identifies the tagged events using object recognition and text-matching algorithms. Once the fabrication event is identified, the system notifies the player that a fabrication event is encountered. In the player interface, players can access the objects from the encountered events, auto-generate 2D fabrication files (SVG or PNG format) of the objects for laser-cutting or paper-cutting. At this point, players can either continue playing or pause the game to fabricate the object~(Figure~\ref{toolkit}-3). More details about the toolkit implementation and the workflow is described in our prior work~\cite{2021fabo}.
		<br>
		<br>
		<b>User Study:</b><br>
		Next, we evaluated the use of our toolkit for integrating fabrication events and activities with existing digital games through a user study. We recruited 12 participants for the study from our institution. The participants (6f, 5m, 1n/b) were students at our institution, were located in North America geographical region, and were of ages between 20-29 years (M=24, STD.=2.82). The participants had a varied experience of playing digital games (ranging from 10+ yrs to never playing games). We recruited the participants through our institution mailing lists with a call for participants for a study on integrating physical fabrication with digital games. Because the study focused on mainly evaluating the toolkit usability (that is designed for non-experts), we specified in our recruitment call that no prior game-design or game-play experience was necessary to participate in the study. 
		<br>
		<br>
		Three days prior to the study, the participants were briefed that the goal of the study was to test our toolkit for integrating fabrication events within existing digital games. They were also asked to choose up to three existing digital games, and up to three gameplay moments per game to integrate with fabrication activities. There were no restrictions or constraints on the games that the participants could choose. Letting the participants choose the games, gameplay moments, and the design of the fabrication events allowed us to test our toolkit and our approach for a variety of games, gameplay moments, and strategies of integrating fabrication activities.
		<br>
		<br>
		We conducted the study remotely for a duration of 60 minutes over a video call using a Zoom setup. During the study, we first re-briefed the participants on the idea of integrating fabrication events with existing games and then demonstrated the use of our toolkit to tag visual onscreen cues for the integration using a demo example. The participants then used the Zoom's remote control feature to use our toolkit to tag cues within their chosen gameplay moments and integrate fabrication events within the games of their choice. Because our toolkit saved all the information of the events in our directory, for example screenshots of the game moments chosen, tagged text and image cues, and the selected objects for fabrication in our directory, this data was available for post study analysis.
		<br>
		<br>
		During the study, we asked the participants to talk us through their design goals, rationale for choosing their games and the gameplay moments for integrating with fabrication, and what they wanted their players to experience. We recorded these semi-structured interviews and gathered feedback in a survey form for our post study analysis.
		<br>
		<br>
		<i><b>Study Results:</b></i><br>
		At the end of the study, the 12 participants altogether integrated fabrication events with 47 gameplay moments within 33 different digital games. These games spanned across several game genres, such as action, adventure, puzzle, etc. The fabricated objects from the integrated events also had a variety of uses from being commemorative trophies and collectibles to being functional gameplay objects, such as maps. Figure \ref{gameplay-moments} shows 8 of the 47 gameplay moments and their respective fabricated objects resulted from the user study. These examples include the following fabricated objects: a customized clothing design for personal collection; a map to help solve the puzzle in the game; a collectible of a war plane destroyed as memorabilia; a custom designed skateboard for personal collection; a rare mask acquired as collectible; and an axe acquired in the inventory as a reminder during gameplay. 
		<br>
		<br>
		A detailed analysis of the results from this study is described in our prior work~\cite{2021fabo}. Note that the fabrication events were not tested with new participants as players. Rather, our research team simply tested the toolkit's success rate in generating the 2D fabrication files for laser-cutting the intended objects from the fabrication events resulted from the study. 
		<br>
		<br>
		Beyond the evaluation of the usability of the toolkit, the results and data from this study offer an opportunity to gain deeper insights from a game design perspective on the integration of fabrication activities with existing game mechanics and its resulting player experiences. As this analysis was beyond the scope of the prior work, we analyze them in our current work.  
		<br>
		<br>
		<img src="images/fig3-designer-ui.png" alt="mosculpt-runner" width="750" style="padding-bottom:0px; margin-bottom:10px"/>
		<br>
		<br>
		<b>
		Figure 3. To integrate fabrication events, designers use FabO's designer interface to (a) capture the screenshot of the gameplay moment (b) tag the on-screen visual content as cues, such as text or images, (c) set event properties, and (d) choose option for object fabrication.
		</b>
		<br>
		<br>
		
		<span class="medium-headline">
		===============START EDITING FROM HERE ++++++++++++++ IMPLEMENTATION
		</span>
		<br>
		<br>
		Figure 6 shows the implementation pipeline of the FabO toolkit which mirrors the framework described in Section 3.1. We implemented the FabO toolkit in Python using the PyQt5 library as a GUI wrapper. In the FabO designer interface, we use the Autopy library to take gameplay screenshots, and display them in an editable OpenCV canvas. This editable canvas allows designers to draw bounding boxes on the loaded screenshot image and mark the text and image cues as well as select the region to monitor for cues. For text extraction from a region, we use OpenCV's thresholding function and Python-tesseract, an optical character recognition (OCR) tool. For processing the image cues, we use list slicing to crop the scene image to the cue region. We save the fabrication events, and the associated cues' properties in a JSON file encoded as a dictionary.  
		<br>
		<br>
		<img src="images/fig6-implementation.png" alt="mosculpt-runner" width="750" style="padding-bottom:0px; margin-bottom:10px"/>
		<br>
		<br>
		<b>
		Figure 6. Implementation pipeline: The FabO toolkit has two components, the designer interface and the player interface, that are written in Python and use PyQt5 as a GUI wrapper
		</b>
		<br>
		<br>
		Players can load this file in the FabO player interface and start monitoring their gameplay. For text cue detection, we capture the screen frame by frame and then use text extraction as described above. To match the extracted text with the tagged text cue, we use the Python FuzzyWuzzy library's Levenshtein Distance calculation and match accuracy to 99\%. For image cue detection, we use Autopy’s find bitmap function to search a screen region pixel by pixel. Once a fabrication event is detected, we use list slicing to crop the region and then process it for object extraction using Sullivan et al.'s GrabCut algorithm from OpenCV. After the players fine-tune the outline, we then extract the object outline with OpenCV's contours function, and export it as an SVG file. 
		<br>
		<br>
		To evaluate the performance and usability of this FabO toolkit, and the experience of using it to integrate fabrication with existing digital games we ran two user studies detailed in the next sections. 
		<br>
		<br>

		<span class="medium-headline">
		USER STUDY 1 - Evaluating FabO for Integrating Fabrication with Existing Games
		</span>
		<br>
		<br>
		In the first user study, we examined FabO's workflow and user's experience for integrating fabrication events within various existing digital games. Insights from the study allowed us to determine how designers can choose  (1) suitable visual content for FabO's workflow and (2) suitable gameplay moments for seamless integration of fabrication within the gameplay. 
		<br>
		<br>
		<b><i>Study Design</i></b><br>
		We recruited 12 participants from our institution (6f, 5m, 1n/b) aged between 20-29 years (M=24, STD.=2.82) and with varied experience of playing digital games (10+ yrs to never playing games). We conducted the 60min study remotely over a video call (Zoom). The participants used the FabO toolkit on our computer via Zoom's remote control.
		<br>
		<br>
		Before the study, we asked the participants to choose up to 3 existing digital games, gameplay moments within those games to embed fabrication events, and associated game objects for fabrication. They could source these gameplay moments either from their own gameplay or from online videos. During the study, we first demonstrated the FabO workflow using the game Pokemon Lets Go. The participants then used the FabO designer interface and their sourced videos to tag as many gameplay moments and associated objects for fabrication as they preferred using text and image cues. They then tested if the FabO player interface successfully detected their embedded fabrication events. Finally, we gathered their feedback through semi-structured interviews and a post-study feedback form.
		<br>
		<br>
		<b><i>Study Results</i></b><br>
		Altogether, the 12 participants attempted to integrate fabrication with 35 existing digital games (2-3 games per participant) across 9 genres by tagging 47 events (1-2 events per game). We tested the success of the fabrication events across three conditions: (1) were the participants able to tag on-screen visual content of their chosen gameplay moment, (2) did FabO identify those moments by scanning for the visual cues, and (3) did FabO generate a fabrication file of a game object for laser cutting. If all three conditions were met, we counted an event as a successful fabrication event. 
		<br>
		<br>
		<img src="images/fig7-us1-results.png" alt="mosculpt-runner" width="750" style="padding-bottom:0px; margin-bottom:10px"/>
		<br>
		<b>
		Figure 7. (a) User study participants tested 35 games (24 successful) across 9 genres. (b) Fabricated game-objects using FabO.
		</b>
		<br>
		<br>
		From the 35 games attempted shown in Figure7a: (1) the participants were able to tag on-screen content for 33 games (94.29 %). In 2 games, they struggled to identify a discrete moment to tag a text or image cue for integration. (2) Within the 33 tagged games, participants tagged 47 events - 15 using text cues and 32 using image cues. Of these 47 tagged events, FabO detected 35 events (74.47 %) - 12/15 text cues (80 %) and 23/32 image cues (71.19 %). In total 24 games had successfully detected events. (3) For the 35 detected events, FabO successfully auto-extracted the fabrication files for all game objects as marked by the participants. Thus, in total, the participants successfully integrated fabrication in 24 out of 35 games (68.57 %) across all three conditions. Figure7b shows the objects that we fabricated from the generated files. These objects ranged from commemorative trophies and collectibles to supportive gameplay tools, such as maps.
		<br>
		<br>
		<b><strong>Study Insights</strong></b><br>
		We studied the successful and failed examples of fabrication events from the study to gain the following insights on choosing suitable visual content and gameplay moments:
		<br>
		<br>
		<b><i>#1 Choosing suitable visual content:</i></b><br>
		When tagging an event, the designer has to find a text or image cue on screen that indicates that the event occurred. While most games offer such discrete cues through text messages or images, some games are continuous and do not contain such cues. An example of a game with a discrete cue is the game Prof. Layton [p2] (Figure 8a), in which a text message appears on-screen when players acquire a coin, thus indicating that the event occurred. However, in the 2 games for which participants failed to integrate fabrication events, i.e., Unrailed [p4] (Figure 8a) and Parkitect [p5], the gameplay was continuous with no discrete cues to indicate event occurrence, i.e., the players built a track and a park continuously, thereby making it difficult to select a discrete moment.
		<br>
		<br>
		<img src="images/fig7-insight-visual-content.png" alt="mosculpt-runner" width="750" style="padding-bottom:0px; margin-bottom:10px"/>
		<br>
		<b>
		Figure 8. Examples from user study where FabO (a) successfully detected the text cues (that had legible text), (b) failed to detect text cues (that were pixelated) (c) onscreen text was tagged as image cue because of the font
		</b>
		<br>
		<br>
		Another important consideration in choosing the visual content is to select cues detectable using computer vision, i.e., extractable font and images with a high contrast background (Figure 8b, c). If the font was too thick, artistic or low-res (Figure 8b-bottom), the text extraction was faulty. Similarly, if the background was too noisy (Figure 8c-bottom), the image cue detection was slow and faulty. To increase the detection speed, some participants used a smaller area with less background noise for monitoring and FabO successfully detected the events. 
		<br>
		<br>
		Finally, to fabricate objects from visual content, it is essential to have them present on-screen at the moment selected for fabrication. When the objects were not visually present on-screen, participants linked external files with the event. However, one participant [p6] addressed this constraint by using FabO's sequencing feature for the game Final Fantasy, by using one fabrication event to trigger another event, wherein the fabrication object was on-screen.
		<br>
		<br>
		<b><i>#2 Choosing gameplay moments suitable for seamlessly integrating with fabrication:</i></b><br>
		When analyzing the successfully embedded fabrication events from the study, we observed that the timing of integration within the gameplay was crucial. We noted that fabrication was integrated either at the start (7/47 events, 15 %), during the gameplay when there are natural pauses (31/47 events, 66 %), or at the end of the gameplay (9/47 events, 19 %) when the player can shift focus to fabrication.
		<br>
		<br>
		<img src="images/fig8-insights-moments.png" alt="mosculpt-runner" width="750" style="padding-bottom:0px; margin-bottom:10px"/>
		<br>
		<b>
		Figure 9. User study #1 examples of gameplay moments when fabrication was integrated at the start, during, or end of the gameplay. [(e): fabrication event, and (o): fabrication object.
		</b>
		<br>
		<br>
		Examples of embedded fabrication events at the start of the gameplay included moments when the player created new objects, such as a dress (Animal Crossing Figure 9-1), customized game-objects, such as their skateboard (Tony Hawk Figure 9-2), or received support objects, such as a map (World of Tanks Figure 9-3). Examples of embedded fabrication events during the gameplay included moments of natural pauses, either because the game paused the playing or the player paused their gameplay voluntarily. Examples of gameplay pauses included moments, such as unlocking characters (Mario Kart Figure 9-4) or powers (Gris Figure 9-6), and destroying characters or objects. Examples of player-based pauses included players updating (Skyrim Figure 9-7) or accessing their inventory (Minecraft Figure 9-8), referencing support objects, such as maps, accessing scorecards or stat cards, and socially interacting with game characters (Ori and the Blind Forest Figure 9-9). Because "these are natural pauses" [p9] when players were not concentrating on playing the game, participants chose these moments as suitable for introducing them to a fabrication activity. Examples of embedded fabrication moments at the end of the gameplay included moments when the players completed building, such as a house (Sims Figure 9-11), or had won the game (Grand Tourismo Sport Figure 9-12). 
		<br>
		<br>
		In summary, we observed that participants were mindful of the gameplay timing while integrating fabrication within it, such that it would not distract or interrupt the players while playing. 
		<br>
		<br>
		While these examples cover the various games that the participants explored, our study does not cover the full design space of existing games. Thus, more extended studies are needed to understand how to choose suitable visual content and gameplay moments for integrating fabrication with existing games while also augmenting the player's experience. 
		<br>
		<br>
		<span class="medium-headline">
		USER STUDY 2 - Evaluating the Player Experience during Gameplay
		</span>
		<br>
		<br>
		In the second user study, we examined player's experience of playing an existing digital game integrated with fabrication events, and then fabricating objects from their gameplay using FabO.  
		<br>
		<br>
		<b><i>Study Design</i></b><br>
		For the study, we selected the game \textit{Pokemon Planet} because it has a short gameplay and an open-ended story line. Using FabO, we embedded fabrication events that corresponded to when players received either a Pokeball or captured a Pokemon. We recruited 12 new participants from our institution (8f, 4m) aged between 17-28 years (M=22.75, STD.=4) with varied experience of playing games from few times a month to everyday. We conducted the 30min study per participant remotely over Zoom, where they played the game for 15 mins on our computer via Zoom's remote control. We did not brief the participants about the FabO system and simply asked them to play the game as they normally would on their own. When they encountered a fabrication event in the game, FabO notified them with a text prompt. At this point, they could either continue playing or pause the game to fabricate the object. For fabrication, the participants first reviewed the auto-generated fabrication files in the FabO player interface and then fabricated the objects, such as Pokeballs and their captured Pokemons using a remote paper-plotter via Zoom's remote control feature, and watched their objects get fabricated over the video call. We then collected feedback on their experience in a semi-structured interview and a post-study feedback form. 
		<br>
		<br>
		<img src="images/fig10-userstudy2-old.png" alt="mosculpt-runner" width="750" style="padding-bottom:0px; margin-bottom:10px"/>
		<br>
		<b>
		Figure 10. (a) User study #2 setup wherein the participants remotely (via Zoom's remote control) played the game PokemonPlanet integrated with fabrication events, (b) fabricated objects from their gameplay using FabO and a remote paper-plotter. (c) Participants' feedback.
		</b>
		<br>
		<br>
		<b><i>Participant Feedback</i></b><br>
		<b><i>Fabrication of Objects was Meaningful:}</i></b> 11 out of 12 (91.6 %) participants found the ability to have physical versions of digital objects from their gameplay meaningful. For example, p4 said <i>"There are many times during a game where I [have] thought it would be amazing to have a physical version of the equipment"</i> and p7 said <i>"I think it can be nice to build collections and to hold pride about."</i> However, p8 highlighted the need for closely integrating fabrication - <i>"The main risk of the modified game is for the fabrication event to feel out of place."</i> Some participants also recommended using the system for educational purposes. For example p12 said <i>"As an educational tool, especially for getting kids excited about fabrication, I can see it being really empowering and engaging while teaching really valuable skills in STEM."</i>
		<br>
		<br>
		<b><i>Choice of Objects for Fabrication:</i></b> When asked if they preferred to choose which objects to fabricate and when to fabricate them, 7 out of 12 (58 %) participants wanted to choose themselves. For example, p3 said <i>"I would love to see players given the opportunity to design and embed their own events as well - to trade in games."</i> In contrast, 5 participants preferred the experience designed by someone else because it builds anticipation. For example, p10 said <i>"the anticipation of fabricating pokemon in real life encourages me to keep playing the game to discover new pokemon...so I can make more collectibles. The excitement and anticipation of playing the game and fabrication game items builds on each other."</i> In addition, p4 said <i>"randomizing the fabrication events rather than having them be predictable is fun!"</i>
		<br>
		<br>
		<b><i>Timing of Fabrication Events:</i></b> 7 out of 12 (58 %) participants found the idea of fabricating objects during their gameplay enjoyable. From the other 5 participants, 3 stated that they preferred to fabricate the objects after the gameplay and not while playing the game as it halted their gameplay. For example, p2 said <i>"depending on the pace of gameplay, e.g., on a mission or adventure, it may feel distracting to keep having to switch out of the game to fabricate."</i> and p12 said <i>"perhaps pausing [the] game to make fab files print-ready was a bit intrusive and detracted a bit from gameplay."</i> 
		<br>
		<br>
		<b><strong>Study Insights</strong></b><br>
		We thus observed that from the player's perspective, it was important that the fabrication does not hinder the gameplay and is integrated meaningfully for a definite purpose. If integrated well, our study participants' feedback shows that it may increase player's motivation, excitement, and engagement with the game without distracting their gameplay.
		

		<br>
		<br>
		<span class="medium-headline">
		
		DISCUSSION
		</span>
		<br>
		<br>
		We illustrated how FabO supports designers in integrating fabrication events with existing digital games. We next discuss the limitations of our toolkit and provide directions for future work:
		<br>
		<br>
		<b><i>Visual Cues Required:</i></b> Because our framework uses on-screen visual content, we cannot extract information from moments that either (1) do not have distinct visual cues or (2) that have non-visual cues, for example sound. To address the first limitation, we can explore if machine learning techniques can be used to automatically identify significant moments and auto-label fabrication objects. For the second limitation, we can expand our system to tag and identify audio cues to include events that may not have distinct visual cues.
		<br>
		<br>
		<b><i>Trade-off in detection speed and object fidelity:</i></b> Because analyzing visual content during the gameplay requires significant computation power, the speed of detection is dependent on the player's screen resolution and the processing power of their computers. While reducing the screen resolution may improve detection speed, it reduces the fabrication file’s fidelity. This trade-off in performance speed and fabrication file’s fidelity can be addressed by using more efficient algorithms for object detection.
		<br>
		<br>
		<b><i>2D fabrication Only:</i></b> Because we use 2D object extraction techniques for generating files, the resulting fabrication files are for 2D fabrication only. However, 3D fabrication, such as 3D printing, can also be integrated with gameplay using our framework by linking custom STL files of 3D objects to the fabrication events. For future versions of our system, we can generate 3D models from 2D visual content by (1) mapping 2D images to 3D models repositories, or (2) reconstructing the 3D geometry from 2D images through advanced graphics techniques, such as multi-view object construction.
		<br>
		<br>
		<b><i>Extending the use of the fabricated objects in games:</i></b> While incorporating the fabricated objects back into the game's mechanics is beyond the scope of our current work, it is an avenue for future work. Toolkits like \textit{Nintendo LABO} already incorporate objects fabricated from 2D materials within games for immersive gameplay. By fabricating tangible objects and configuring them to influence the gameplay can integrate the loop of play and fabrication more tightly.
		<br>
		<br>
		<b><i>Educational and social maker-games:</i></b> The design of our framework also allows for applications in educational and social maker games. For instance, an educator can use the sequencing feature of our toolkit to embed increasingly difficult fabrication activities for their students. Similarly, in a social setting with multiple users, every user can use the designer interface to design unique fabrication events within the game or add to each others' fabrication events. The users can then play each others' unique versions or the combined version, encounter the unique fabrication events and fabricate objects, thereby creating novel social interactions using gaming and fabrication.  
		<br>
		<br>

		<span class="medium-headline">
		CONCLUSION
		</span>
		<br>
		<br>
		In conclusion, we showed that fabricating objects from player's gameplay, such as collectibles, can be accomplished using our FabO framework, which allows designers to use on-screen content instead of source files for integration and auto-generation of fabrication files. We implemented our framework in the FabO toolkit and demonstrated FabO's workflow that uses computer vision for tagging on-screen visual cues for embedding events and extracting on-screen objects for fabrication. Through two user studies, we showed that FabO successfully allowed the participants to integrate fabrication with a wide variety of existing games to augment player's experience. We discussed the insights from our studies for choosing suitable on-screen visual content and gameplay moments for seamlessly integrating fabrication with the myriad existing games, thereby tapping their potential to expand players' engagement through fabrication.  
		<br>
		<br>
		

		<span class="medium-headline">
		ACKNOWLEDGMENTS
		</span>
		<br>
		<br>
		We thank Supramaya Prasad and Joshua Verdejo for their input in the project. We thank the <a href="https://mitili.mit.edu/">MIT Learning Initiative</a> and the MIT.nano NCSoft innovations in gaming technology initiative for partial funding of this research. This work is also supported by the National Science Foundation under Grant No. 2008116.
		<br>
		<br>


		<br>
		<br>
		<br>
		<br>
		<br>
		<br>
		<br>
		<br>
		<br>
		<br>


	</div>
	</div>
</div>

<div class="container">
	<div class="row">
		<div class="col-md-12 footer" style="text-align: center;">
			<span class="copyright">
			Since 2017 &copy; MIT CSAIL (HCI Engineering group) [redesign by
			<a href="http://punpongsanon.info/" target="_blank" style="text-decoration:none; border-bottom:0px">
			moji
			</a>].
			All Rights Reserved.

			<a href="http://mit.edu/" target="_blank" style="text-decoration:none; border-bottom:0px">
			<img src="http://hcie.csail.mit.edu/images/logo/mit.svg" alt="MIT" class="footer-logo" />
			</a>
			<a href="http://csail.mit.edu/" target="_blank" style="text-decoration:none; border-bottom:0px">
			<img src="http://hcie.csail.mit.edu/images/logo/csail.svg" alt="CSAIL" class="footer-logo"/>
			</a>
			<a href="http://hci.csail.mit.edu/" target="_blank" style="text-decoration:none; border-bottom:0px">
			<img src="http://hcie.csail.mit.edu/images/logo/hci.svg" alt="HCI" class="footer-logo"/>
			</a>
			</span>
		</div>
	</div>
</div>

<!-- Bootstrap -->
<script type="text/javascript" src="https://hcie.csail.mit.edu/js/bootstrap.min.js"></script>
<!-- header -->
<script type="text/javascript" src="https://hcie.csail.mit.edu/js/headerstrap-for-subpage.js"></script>
<!-- lightbox -->
<script type="text/javascript" src="../../js/lightbox.js"></script>

</body>
</html>
