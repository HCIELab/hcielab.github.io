<!DOCTYPE html>
<html>
<head>
	<title>HCI Engineering Group</title>
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

	<!-- CSAIL ICON -->
	<link rel="CSAIL" href="../../images/icon/csail.ico" type="image/x-icon" />

	<!-- Bootstrap -->
	<link href="../../css/bootstrap.css" rel="stylesheet">
	<link href="../../css/custom-style.css" rel="stylesheet">

	<!-- jQuery -->
	<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>

	<!-- Google Fonts -->
	<link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Abel" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Barlow" rel="stylesheet">

	<!-- Google Analytic -->
	<script type="text/javascript" src="../../js/analytics.js"></script>

	<style>
	.etech-sch-col1 {width:60px; border: 1px solid black;padding:10px;}
	.etech-sch-col2 {width:120px; border: 1px solid black;padding:10px;}
	.etech-sch-col3 {width:450px; border: 1px solid black;padding:10px;}
	.etech-sch-col4 {width:70px; border: 1px solid black;padding:10px;}
  .etech-sch-col5 {width:70px; border: 1px solid black;padding:10px;}
  /*.etech-sch-col6 {width:170px; border: 1px solid black;padding:10px;}*/
  ul {
    padding:0px;padding-left:10px;margin:0px;
  }
	</style>
</head>

<body>
<header class="main_header">
	<!-- to be filled by javascript, see header.html -->
</header>

<section class="main_container">
	<div class="container">
    <div class="row nothing">

      <section class="col-md-8 pull-right main-content">
</br></br></br></br>
        <h4 class="medium.headline"><a href="6810-engineering-interactive-technologies.html">6.810 Engineering Interactive Technologies (fall 2020)</a><br></h>
        <h2 class="headline">Problem Set Series: Multi-Touch Pad</h2>


<img src="images/pset2-overall.png" width="400px">
<img src="images/pset3/multi-touch_3-fingers.png" width="300px"> <br>

          <hr>


<h2 class="headline">Problem Set 3 (due Friday, Oct. 23, 2020, 11.59pm)</h2>

Now that you have the hardware ready and Arduino sensing code prepared, you will write some code for the visualization part of your multi-touch pad. In particular, you are going to do the following four steps:<br>

<ol>
	<li>Read the multi-touch sensing data (generated by your PSet2 Arduino code) from serial port and save them properly. </li>
	<li>Set the noise baseline.</li>
	<li>Set the background image color update and perform bicubic interpolation.</li>
	<li>Implement blob detection.</li>
</ol>
<br>

<h3>Skeleton Code</h3>

Start by downloading <a href="software/pset3_visualization_skeleton.zip">the skeleton code for the PSet3 from  here</a>. <br>
Before you can execute it, you first have to install two libraries (see next step). <br><br>

<h3>Install external libraries</h3>

For this PSet, we will be using two Processing libraries: 
<ol>
	<li>OpenCV (a library that helps with image processing, in our case we will draw our touch signals into an image, see picture at start of pset3)</li>
	<li>BlobDetection (a library that helps to find blobs inside of images, in our case the blobs are the touch points on the multi-touch pad)</li>
</ol>

You can install them directly in Processing by going to:<br>
<b>Sketch/Import Library/Add Library</b> and searching for their name.<br><br>

<img src="images/pset3/processing-library-opencv.png" width="370px">
<img src="images/pset3/processing-library-blob-detection.png" width="370px"> <br><br>


<h3>(1) Read the multi-touch sensing data</h3><br>

<b>Refresher from PSet2</b><br>
In pset2, you already wrote the <b>Arduino</b> code that reads the receiver pins from the multi-touch pad and writes the resulting data onto the serial port in the following way: <br><br>

<pre>
0,50,83,58,79,108,75,82,54   //columm0, row0val, row1val, row2val
1,55,92,120,84,63,61,88,53   //columm1, row0val, row1val, row2val
2,61,64,73,66,92,78,67,57
3,65,117,116,84,48,81,91,71
4,65,128,116,54,76,81,88,59
5,61,86,66,54,114,78,64,64
6,59,86,120,83,85,75,93,63
7,56,86,116,70,72,83,80,64
8,23,82,74,68,98,64,62,52
...
</pre> <br>

<b>Read Data from Serial Port Into Processing</b><br>
Next, you need to read this data from the serial port into Processing.<br>
We have already shown you how to read data from the serial port into Processing in Lab 1 & 2 and you can check your prior code from back then to see how to do it.<br><br>

In the skeleton code, put your code for reading the data into the <b>readSerial()</b> function: <br>
<img src="images/pset3/readSerial-skeleton-code.png" width="700px"> <br>

<b>Save Data for One Complete Scanning Pass into a 2D Array</b><br>
The data for a single pass on all columns and rows should be saved into a 2D array.<br>
When considering the size of your 2D array, remember that we build a 9x8 multi-touch pad.<br>
Printing the 2D array to the Processing command line should look something like this:<br><br>

<img src="images/pset3/serial-read-array.png" width="700px"> <br><br>



<h3>(2) Set the noise baseline</h3>

As you probably noticed when looking at the sensing data in the Arduino serial monitor in PSet2, there are always some readings in each ADC channel. <br>
These are usually what we called the "noise" in signal processing. <br>

In order to eliminate the noise and visualize more "clean" data, we will be the setting the noise baseline for our multi-touch pad. <br><br>

The idea here is quite straightforward, we will take the first <b>2 seconds</b> of the non-touch sensing data and store them as the noise baseline. <br>
For all the raw sensing data coming after the baseline is set, we will subtract the the noise value from the raw value, and use those for actual visualization. <br>
Each "value" should has its own noise baseline (i.e. we are having 8x9 = 72 values in total) for better performance.<br><br>

Feel free to implement this part the way you wnat as long as it satisfies the "record the first 2 seconds" + "noise baseline for each value" requirements. <br>
For example, you can record all the baseline data in a 2D array of the same size as the sensing data array from part 1. <br>
Notice that you should also store "how many" times the noise data are recorded during the 2 sec time frame, and divide the overall noise value by that. <br>
Please store the individual recorded times for each "value" and do the division (i.e. we are having 8x9 = 72 values in total)for better performance.<br><br>

You should be implementing this in the <b>setBaseLine()</b> function, and change the <b>boolean baseLineSet</b> in the skeleton code to "true" once the baseline is set: <br>
<img src="images/pset3/setBaseLine-skeleton-code.png" width="700px"> <br>


<h3>(3) Set the background image color and bicubic interpolation</h3>
Now that we have the "clean" sensing values, we will scale them up/down into the values that distinguish them enough and optimized for visualization, and interpolate them into a bigger and "smoother" plane (in our case, 500px * 500px). <br><br>

For the first part, since we are "visualizing" sensing values by color (in RGB),  we will scale them up/down to range of 0-255. <br>
Also for the convenience of visualization, we will construct a PImage that has the same size of our sensing data, and perform the amplification/suppression there. <br>
You will find the <b>map()</b> function in Processing to be helpful <b>(note: not necessarily "max out" when touched, try out a few numbers to find the most suitable factors for you circuit, in terms of visualization)</b>. <br><br>

You should be implementing this in the <b>setColors()</b> function in the skeleton code: <br>
<img src="images/pset3/setColors-skeleton-code.png" width="700px"> <br>

Once have the scaled values (in PImage), we will then interpolate them into a bigger and "smoother" plane (500px * 500px) to fit our display window (also 500px * 500px). <br>
We will implement this via bicubic interpolation. <br>

<h3>Bicubic Interpolation</h3>

Recall from Lab 1 & 2, you have implemented a (simple) linear interpolation for the slider. <br>
The bicubic interpolation has the similar idea, except for it is in 2D, which makes it perfect for image processing. <br><br>

In image processing, bicubic interpolation is often chosen over bilinear or nearest-neighbor interpolation in image resampling, when speed is not an issue.<br> 
In contrast to (bi-) linear interpolation, which only takes 4 pixels (2×2) into account, bicubic interpolation considers 16 pixels (4×4). <br>
Images resampled with bicubic interpolation are smoother and have fewer interpolation artifacts. <br><br>

You can compare the difference between (bi-) linear & (bi-) cubic interpolations over the following interpolation results based on the same data points (5x5): <br>
<img src="images/pset3/linear-interpolation.png" width="300px"> 
<img src="images/pset3/cubic-interpolation.png" width="300px"> <br><br>

Luckily, you do not have to implement the whole interpolation calculation from scratch, as you can using the "wheels" from OpenCV. <br>

You should be implementing this in the <b>interpolate()</b> function in the skeleton code: <br>
<img src="images/pset3/interpolate-skeleton-code.png" width="700px"> <br>

Once you finished this part, you should be seeing the following when the multi-touch pad is not touch: <br>
<img src="images/pset3/UI-no-blob-no-touch-1.png" width="350px"> 
<img src="images/pset3/UI-no-blob-no-touch-2.png" width="350px"> <br>

And something like this when touched, with the correct relative position "light up" (1 finger touching on the left, 2 fingers touching on the right): <br>
<img src="images/pset3/UI-no-blob-touch-1.png" width="350px"> 
<img src="images/pset3/UI-no-blob-touch-2.png" width="350px"> <br>

<h3>(4) Implement blob detection</h3>

The last part of this PSet is to implement the "blob" detection for "touched location" of the multi-touch pad. <br>
The blob detection is implemented on top of the interpolated image (e.g. PImage of 500px * 500px) from part 3. <br><br>

You will be drawing 2 things on each detected blob: 1) the edge of the blob, and 2) the center point of the blob. <br>
The blob detection is implemented via the BlobDetection library. For more details, you can look at <a href="http://www.v3ga.net/processing/BlobDetection/index-page-documentation.html">here </a>. <br><br>

You should be implementing this in the <b>drawBlobsAndEdges()</b> function in the skeleton code: <br>
<img src="images/pset3/drawBlobsAndEdges-skeleton-code.png" width="700px"> <br>

Once you finished this part, you should be seeing the following differences compared to Part 3 (Part 3 vs Part 4, with one finger touching at the same location): <br>
<img src="images/pset3/UI-no-blob-touch-1.png" width="350px"> 
<img src="images/pset3/UI-blob-touch-1.png" width="350px"> <br><br>

When you have multiple fingers touching the multi-touch pad, you should see something similar to the following (2 fingers touching vs. 3 fingers touching): <br>
<img src="images/pset3/UI-blob-touch-2.png" width="350px"> 
<img src="images/pset3/UI-blob-touch-3.png" width="350px"> <br>

<br>

<h3>Upload your Processing Code and pictures of Your visualization UI</h3>

For grading, please upload the following to your google drive student folder:<br>

<ul>
	<li>the .pde file of your Processing program</li>
	<li>3 photos showing your Processing UI works with one, two, and three fingers touching the multi-touch pad</li>
	<li>a short video showing the Processing program working, i.e. show that the Processing UI correctly identifying one, two, and three fingers respectively touching the multi-touch pad and displays at the correct locations. Make sure the Processing UI, your multitouch pad and your fingers are visible at the same time.</li>
</ul>

<h3>Grading</h3>

We will give 25 pts in total:
<ul>
	<li>5 pts: you finished all for steps of the task.</li>
	<li>5 pts: read sensing data from serial port and save them correctly.</li>
	<li>5 pts: set the noise baseline correctly, e.g. record the first 2 sec of the sensing data as noise baseline.</li>
	<li>5 pts: update the background image color and perform bicubic interpolation correctly.</li>
	<li>5 pts: implement blob detection correctly.</li>
</ul>



        <br />
        <br />
      </section>

      <aside class="col-md-4 pull-left">
         <br /> <br /> <br /> <br />
<!-- 				 <h4>Pset Steps</h4><br>
				 <ul>
		 			<li><a href="#pset1">pset1 (due Sept. 21, 11.59pm): laser cut and bend the acrylic base</a><br /></li>
		 			<li><a href="#pset2">pset2 (due Oct. 5, 1pm): insert LEDs, add USB connecting and solder everything</a><br /></li>
		 			<li><a href="#pset3">pset3 (due Oct. 19, 1pm): write touch recognition so that you can determine (x,y) location of each finger</a><br /></li>
		 			<li><a href="#pset4">pset4 (due Oct. 26, 1pm): add an application of your choice</a><br /></li>
				</ul>
				<br /> <br /> <br /> <br />
        <img src="../2018-fall-6810/images/multi-touch-pad/iap1.jpg" width="220px">

		<img src="../2018-fall-6810/images/multi-touch-pad/iap2.jpg" width="220px">

		<img src="../2018-fall-6810/images/multi-touch-pad//iap3.jpg" width="220px">

		<img src="../2018-fall-6810/images/multi-touch-pad/iap4.jpg" width="220px">

		<img src="../2018-fall-6810/images/multi-touch-pad/iap5.jpg" width="220px">
 -->



        <!-- Publication -->

        <br><br><br><br><br>

        <!-- Publication -->

<!-- <h4>Side Bar</h4><br>

    <ul>
      <li>Prof. Stefanie Mueller (Instructor)</li>
      <li>Lotta-Gili Blumberg (TA)</li>
      <li>Xin Wen (UTA)</li>
      <li>Loren Maggiore (LA)</li>
      <li>Mark Chounlakone (LA)</li>
    </ul>
 -->
</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>
</br>

      </aside>

    </div>
  </div>
  </div>
</section>

<div class="container">
	<div class="row">
		<div class="col-md-12 footer" style="text-align: center;">
			<span class="copyright">
			Since 2017 &copy; MIT CSAIL (HCI Engineering group) [redesign by
			<a href="http://punpongsanon.info/" target="_blank" style="text-decoration:none; border-bottom:0px">
			moji
			</a>].
			All Rights Reserved.

			<a href="http://mit.edu/" target="_blank" style="text-decoration:none; border-bottom:0px">
			<img src="../../images/logo/mit.svg" alt="MIT" class="footer-logo" />
			</a>
			<a href="http://csail.mit.edu/" target="_blank" style="text-decoration:none; border-bottom:0px">
			<img src="../../images/logo/csail.svg" alt="CSAIL" class="footer-logo"/>
			</a>
			<a href="http://hci.csail.mit.edu/" target="_blank" style="text-decoration:none; border-bottom:0px">
			<img src="../../images/logo/hci.svg" alt="HCI" class="footer-logo"/>
			</a>
			</span>
		</div>
	</div>
</div>

<!-- Bootstrap -->
<script type="text/javascript" src="../../js/bootstrap.min.js"></script>
<!-- header -->
<script type="text/javascript" src="../../js/headerstrap-for-subpage.js"></script>

</body>
</html>
