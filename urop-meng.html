<!DOCTYPE html>
<html>
<head>
	<title>HCI Engineering Group</title>
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

	<!-- CSAIL ICON -->
	<link rel="CSAIL" href="/images/icon/csail.ico" type="image/x-icon" />

	<!-- Bootstrap -->
	<link href="css/bootstrap.css" rel="stylesheet">
	<link href="css/custom-style.css" rel="stylesheet">

	<!-- jQuery -->
	<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>

	<!-- Google Fonts -->
	<link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Abel" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Barlow" rel="stylesheet">

	<!-- Google Analytic -->
	<script type="text/javascript" src="js/analytics.js"></script>
</head>

<body>
<header class="main_header">
	<!-- to be filled by javascript, see header.html -->
</header>

<section class="main_container">

<div class="container">
	<div class="row" style="padding-bottom:0px;margin-bottom:0px">
	</br>
	</br>
	</br>
	<h3 class="headline">UROP / MEng with us</h3>
	<hr>
	Before applying please read the information below carefully.<br>

	<div class="row" style="padding-bottom:0px;margin-bottom:0px">
	</br>
	</br>

		<div class="col-md-8" style="text-align: left;">
			<h3 class="headline">What do we look for in a UROP / MEng?</h3>
			<hr>
			<ul>
				<li>When getting started in our lab, UROPs / MEng students typically start out by supporting one of our PhD students or postdocs on their research project.</li>
				<li>These research projects will be submitted for publication at the top HCI conferences ACM CHI and ACM UIST with the UROP / MEng-es co-authoring the papers and in some cases also traveling to the conference to give part of the talk or a live demo.</li>
				<li>We only look for UROPs/MEng-es seriously interested in becoming part of our research group. Each research project is important for the career of one of our PhD students or postdocs--we rely on each UROP and MEng to be a reliable team member and committed to making the project a success.</li>
				<li>In turn, you will be a member of a family-style research team with great mentoring, learn many new skills, and have a professional looking project on your portfolio.</li>
				<li>While we love to hear your own project ideas, the standard path in our lab is to first join an on-going research project with a senior mentor (PhD student or postdoc). Identifying a novel research contribution often takes years of training and is even a hard task for a mid-level PhD student.</li>
			</ul>

		<h3 class="headline">UROP: Time Commitment + Pay/Credits</h3>
			<hr>
			<ul>
				<li>UROPs will work ca. 8-10 hours per week. We care about outcomes and do not track your hours. However, we expect everyone to be present in the lab for most of this time to keep the communication paths short.</li>
				<li>You can do your UROP for pay or for credit.</li>
				<li>Please reach out before the following deadlines: spring semester: February 1, summer semester: April 1, fall semester: September 1, IAP: December 1).</li>
				<li>What if I don't have the skills yet? We do not expect you to already know everything--if you love the project and you are willing to put in the energy and time, we will be happy to teach you the necessary skills.</li>
			</ul>

		<h3 class="headline">MEng: Time Commitment + Pay</h3>
			<hr>
			<ul>
				<li>MEng-es are expected to spend at least 20 hours per week on their project. We care about outcomes and do not track your hours. However, we expect everyone to be present in the lab for most of this time to keep the communication paths short.</li>
				<li>You can do 2-, 3-, or 4-semester MEng-Thesis projects.</li>
				<li>Before applying to the lab, you need to have secured a TA position since we don't have funding to support MEng students (please mention the TA position in your email).</li>
			</ul>

		<h3 class="headline">Application Process</h3>
			<hr>
			If you are interested in working with us, send Prof. Mueller an email with the following:
			<ul>
				<li>what position you are interested in (UROP/MEng)</li>
				<li>when you would like to start</li>
				<li>your CV</li>
				<li>a website showing your previous projects or a project portfolio as pdf</li>
				<li>your latest grade transcript</li>
				<li>two names of people who we can ask for a short recommendation (e.g., previous UROP or internship mentors)</li>
			</ul>

			Prof. Mueller will then forward your materials to her PhD students and Postdocs who will then get back to you in case they have an opening. To get an idea of the type of projects our UROPs and MEng-es work on, you can read more below or go to the publication list on our homepage.<br><br>
			<!-- // the PhD student or postdoc you want to work with (see project descriptions and contact information below) -->


<!-- 		<h3 class="headline">Current Topics</h3>
			<hr>
			All of our project openings are posted on the UROP portal. <br>
			Note that this does not mean they are only for UROPs , MEng-es can also reach out to us for those projects.<br><br> -->
<!--
			<b>Current UROP/MEng Openings:</b>
			<ul>
				 <li><a href="https://urop.mit.edu/content/slicehub-ecosystem-re-using-exploring-and-sharing-slicing-results">SliceHub: An Ecosystem for Re-using, Exploring, and Sharing of Slicing Results</a></li> -->
				<!-- <li><a href="https://urop.mit.edu/content/3d-sensors-rapid-prototyping">3D Sensors for Rapid Prototyping</a> -->
				<!-- <li><a href="https://urop.mit.edu/content/making-machine-makes-machines">Making a Machine that Makes Machines</a></li>
			</ul>
-->


		<h3 class="headline">Previous Projects</h3>
		<hr>
		Below you find a summary of projects that resulted in published research papers with UROPs and MEng-es co-authoring the papers.<br><br>

		<div class="col-md-2" style="text-align: left;">
	<a href="https://hcie.csail.mit.edu/"><img src="research/laserfactory/images/laserfactory-thumbnail2.png" width="110px"></a>
</div>
<div class="col-md-10" style="text-align: left;">
	<div class="medium-headline" style="padding-bottom:10px">
		<a href="https://hcie.csail.mit.edu/">LaserFactory (ACM CHI 2021 Paper)</a>
	</div>
	This project was led by HCIE <a href="http://martinnisser.org/">PhD student Martin Nisser.</a><br><br>
	<div class="col-md-15" style="text-align: left;">
		<img src="images/people/christina-liao.jpg" alt="christina Liao" class="img-urop img-rounded">
	</div>
	<div class="col-md-10" style="text-align: left;">
		<b>Christina Liao (MEng):</b> Christina developed the software pipeline for a novel fabrication method that uses a laser cutter to automatically create fully-functional devices that work immediately after fabrication is complete. The software pipeline she designed consists of a design interface, in which users can define the circuitry and geometry of the device to fabricate, and a post-processing system that transforms the design into machine instructions that a laser cutter uses to fabricate the device. With this pipeline, users can design and fabricate high-fidelity devices without needing to know the specifics behind the fabrication process. <br>

						Tools/Programming languages: Javascript, Python, Blender, Adobe Illustrator.<div style="background:orange">2021 Charles & Jennifer Johnson Best Computer Science MEng Thesis Award</div><br><br>
	</div>

	<div class="col-md-15" style="text-align: left;">
		<img src="images/people/aradhana-adhikari.jpg" alt="aradhana adhikari" class="img-urop img-rounded">
	</div>
	<div class="col-md-10" style="text-align: left;">
		<b>Aradhana Adhikari (MEng):</b> Ara developed a 3D visualization tool in Blender for LaserFactory's fabrication system. The 3D visualization tool is a two part system. One part generates 3D models of the fabrication output from 2D SVG design files. In addition to the 3D model, the tool also creates an animated visualization of all the fabrication steps involved in creating the design, which includes all steps for creating the geometry of the design as well as the steps for building th electronic circuit. These 3D models and animations are created using Blender’s Python API, and the results are displayed in a Blender window. This tool is used to visualize designs with many different features, including LED and quadrotor control circuits, structures with holes, and also 3D structures created through folding. <br>

						Tools/Programming languages: Python, Blender.<br><br>
	</div>

		</div>







        <div class="col-md-2" style="text-align: left;">
			<a href="https://hcie.csail.mit.edu/"><img src="research/fabricaide/images/fabricaide-thumbnail2.png" width="110px"></a>
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				<a href="https://hcie.csail.mit.edu/">Fabricaide (ACM CHI 2021 Paper)</a>
			</div>
			This project was led by HCIE <a href="http://tichamelody.com/">PhD student Ticha Sethapakdi.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/adrian-sy.jpg" alt="Adrian Sy" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Adrian Sy (MEng):</b> I implemented a fast 2D packing algorithm that packs parts of a laser-cut design onto material sheets that may have previously cut holes. The algorithm produces comparable-quality solutions 4 times faster than Deepnest, a state-of-the-art open-source nesting tool. I also built the Docker image to make Fabricaide easier to install onto participants' machines for the remote user study. <br>

                Tools/Programming languages: C++, Python, Docker.<br><br>
			</div>
        </div>

        <div class="col-md-2" style="text-align: left;">
			<a href="research/sprayableuserinterfaces/main.html"><img src="research/chromoupdate/images/chromoupdate-thumbnail.png" width="110px"></a>
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				<a href="research/sprayableuserinterfaces/main.html">ChromoUpdate (ACM CHI 2021 Paper)</a>
			</div>
			This project was led by HCIE <a href="http://michaelwessely.com/">Postdoc Michael Wessely.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/cattalyya-nuengsigkapian.jpg" alt="Cattalyya Nuengsigkapian" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Cattalyya Nuengsigkapian (MEng):</b> I developed a multithreaded optimization algorithm for reprogramming multi-color textures, which reduces the reprogramming time by half compared to previous work (PhotoChromeleon). I implemented multi-round optimization for better color quality and supported digital previews of the resulting pattern on a Blender 3D model.
                I implemented a light controller and camera capture in Python to automatically collect and generate an activation and deactivation graph of dye color changes over time in MATLAB.<br>

                Programming languages: Processing(Java), Python, MATLAB.<br><br>
			</div>
        </div>


		<div class="col-md-2" style="text-align: left;">
			<!-- <a href="research/curveboard/curveboard.html"> --><img src="research/morphsensor/morphsensor-thumbnail-image.png" width="110px"><!-- </a> -->
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				<!-- <a href="research/curveboard/curveboard.html"> -->MorphSensor (ACM UIST 2020 Paper)<!-- </a> -->
			</div>
			This project was led by HCIE <a href="https://www.junyizhu.com/">PhD student Junyi Zhu.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/yunyi-zhu.jpg" alt="Yunyi Zhu" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Yunyi Zhu (SuperUROP):</b> I developed the MorphSensor 3D editor that can load existing sensor modules, rearrange their components on the 3D prototype object, and export the design for fabrication. I also built various initial breadboard circuits for MorphSensor applications, including N95 mask, blue light monitoring glasses etc. Tools/Programming Languages used: Rhino 3D, Python, Arduino, C. <br> <span style="background:orange">MIT EECS Best SuperUROP Award 2019</span>
				</br><br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/jiaming-cui.jpg" alt="Jiaming Cui" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Jiaming Cui (UROP):</b> I developed the sensor module database for the MorphSensor system. I also built initial versions of MorphSensor via kapton tapes, laser cutter and copper wire sewing. I designed the final MorphSensor footprints (the Bigfoot) in EAGLE, and implemented the Bigfoot auto-generation on unrecorded SMD footprints via EAGLE ULP. Tools/Programming Languages used: Rhino 3D, Python, EAGLE ULP, laser cutter.
				</br><br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/leon-cheng.jpg" alt="Leon Cheng" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Leon Cheng (UROP):</b> I developed an algorithm embedded within MorphSensor system that automatically places electronic components from EAGLE sensor module file in a valid layout onto a custom-formed board. I worked on generating initial fabrication guide files for exported sensor modules from MorphSensor system. I also worked on extracting logic wire connections from EAGLE files as json files for MorphSensor system. Tools/Programming Languages used: Rhino 3D, Python, EAGLE
				</br><br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/jackson-snowden.jpg" alt="Jackson Snowden" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Jackson Snowden (UROP):</b> I designed the initial footprints (BigFoot) used in the project and later verified these designs after receiving the fabricated boards. Tools/Programming Languages used: KiCAD, EAGLE.
				</br><br></br><br>
			</div>
		</div>


		<div class="col-md-2" style="text-align: left;">
			<a href="research/sprayableuserinterfaces/main.html"><img src="research/sprayableuserinterfaces/sprayableuserinterfaces-thumbnail.png" width="110px"></a>
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				<a href="research/sprayableuserinterfaces/main.html">Sprayable User Interfaces (ACM CHI 2020 Paper)</a>
			</div>
			This project was led by HCIE <a href="http://michaelwessely.com/">Postdoc Michael Wessely.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/carlos-lozada.jpg" alt="Carlos Castillo Lozada" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Carlos Castillo (UROP):</b> This project included an end-to-end fabrication pipeline from a digital design tool to the fabrication of large UIs using airbrush spraying. I implemented the digital design toolkit in the 3D editor Blender. I implemented a set of tools for touch sensors, sliders, proximity sensors and electroluminescent displays that lets users draw them on a 3D object. The full design can be exported as 2d stencils and as 3D projections. Tools/Programming Languages used: Python(Blender), Processing(Java). <span style="background:orange">MIT EECS Licklider Best UROP Award 2020</span><br><br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/jackson-snowden.jpg" alt="Jackson Snowden" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Jackson Snowden (UROP):</b> I created a capacitive touch sensing driver on an Arduino platform for sensing interactions with sprayed-on contacts. Then, touch inputs were used to drive Philips Hue lights using a custom Python script and to play audio using an Arduino-SD card interface.
    			I also created a touch display driver by utilizing a switching circuit to deliver power to an electroluminescent display while receiving touch input from the same display. This required me to design and fabricate a custom circuit as well as write extensive Arduino software to drive the circuit. Later, I adapted the existing touch sensing driver to do proximity sensing. This involved several filtering techniques to attain maximum sensitivity while rejecting 60 Hz noise from the surroundings. This new software was used to detect swipe gestures and control a photo album. Tools/Programming Languages used: This project primarily required me to use low-level C to get high performance from the Arduino. I was also able to prototype some simple circuits, create a multi-layer PCB design, and fabricate the final PCB by hand.
				</br><br>
			</div>
		</div>


		<div class="col-md-2" style="text-align: left;">
			<a href="research/curveboard/curveboard.html"><img src="research/curveboard/curveboard-thumbnail.jpg" width="110px"></a>
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				<a href="research/curveboard/curveboard.html">CurveBoard (ACM CHI 2020 Paper)</a>
			</div>
			This project was led by HCIE <a href="https://www.junyizhu.com/">PhD student Junyi Zhu.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/Lotta-Blumberg.jpg" alt="Lotta Blumberg" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Lotta Blumberg (MEng):</b> Explored various fabrication methods for CurveBoards and finalized the 3D printing + conductive silicone mixing & injection fabrication pipeline. Fabricated various CurveBoard models, including bracelet, helmet, headphones, frisbee etc. Evaluated the conductivity & durability of the conductive silicone, and evaluated the fabricated CurveBoards via a user study. Tools/Programming Languages used: 3D printer, conductive inkjet printing, conductive silicone, Arduino, C.
				<br><br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/yunyi-zhu.jpg" alt="Yunyi Zhu" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Yunyi Zhu (SuperUROP):</b> I developed the CurveBoard interactive 3D editor that converts an arbitrary geometry into a CurveBoard model. This includes the algorithm of auto-generating bus channels, the UI for adding and deleting channels, as well as performance engineering for converting the channel information into the final CurveBoard 3D model. I also designed various CurveBoard models, including navigation helmet, interactive headphones, frisbee. Tools/Programming Languages used: Rhino3D. <br><span style="background:orange">MIT EECS Best SuperUROP Award 2019</span>
				</br><br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/xin-wen.jpg" alt="Xin Wen" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Xin Wen (UROP):</b> Xin helped out the last couple of weeks building examples. Xin built an interactive CurveBoard navigation helmet for cyclists. The helmet indicates the routing direction via vibration buzzers on right and left sides, and has turning and stop signal led matrices. Tools/Programming Languages used: Rhino 3D, 3D printer, Arduino, C.
				</br><br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/kevin-shum.png" alt="Kevin Shum" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Kevin Shum (UROP):</b> Kevin also hopped onto the project to help with last minute example building. Kevin built a pair of interactive CurveBoard headphones that is capable of receiving radio and music playing, with sound frequency visualization on a led matrix. Tools/Programming Languages used: Rhino 3D, 3D printer, Arduino, C.
				</br><br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/jessica-quaye.jpg" alt="Jessica Quaye" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Jessica Quaye (UROP):</b> Finally, Jessica helped with example by building the circuit on CurveBoard trinity bracelet and Utah Teapot models shortly before the deadline. Tools/Programming Languages used: Rhino 3D, 3D printer, Arduino, C.
				</br><br></br><br>
			</div>
		</div>


		<div class="col-md-2" style="text-align: left;">
			<a href="research/gid/gid.html"><img src="research/gid/gid-thumbnail.png" width="110px"></a>
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				<a href="research/gid/gid.html">G-ID (ACM CHI 2020 Paper)</a>
			</div>
			This project was led by HCIE <a href="http://www.dogadogan.com/">PhD student Doga Dogan.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/andrew-churchill.jpg" alt="Andrew Churchill" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Andrew Churchill (UROP):</b>

				I started by researching, designing, and iterating on a computer vision algorithm to detect the shape of a 3D printed object’s internal structure. This meant several tries at finding the right algorithm, as well as lots of learning about how to clean up noisy images to get something the algorithm could even work on in the first place. Then, once I had a working Python prototype for the algorithm, I rewrote it in C++, and wrote an Android app which used that C++ code on images from the phone’s camera to detect the internal structure. I also incorporated another computer vision algorithm written by Doga, which was based on 2D Fourier transforms.

				<br> Tools/Programming Languages used: Python, OpenCV, C++, Android, Java
				<br><br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/leon-cheng.jpg" alt="Leon Cheng" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Leon Cheng (UROP):</b>
				I developed a coffee machine prototype with custom electronics to illustrate the capabilities of individually identifiable 3D printed mugs. I built this by disassembling a standard coffee machine and then modifying and reconstructing it, using 3D modeling and printing to build a mug stand and a LCD screen to form an interactive electronic coffee dispenser.<br>
				Tools/Programming Languages used: Languages used: Arduino, Rhino, Grasshopper.

				</br><br>
			</div>
		</div>


		  <div class="col-md-2" style="text-align: left;">
			<a href="research/photochromeleon/photochromeleon.html"><img src="research/photochromeleon/images/reprogramming%20new%20textures.png" width="110px"></a>
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				<a href="research/gid/gid.html">Photo-Chromeleon (ACM UIST 2019 Paper, Best Paper Award)</a>
			</div>
			This project was led by HCIE Postdocs <a href="http://ultra-jin.com/" target="_blank">Yuhua Jin</a>, <a href="https://www.isabelqamar.co.uk/" target="_blank">Isabel Qamar</a>, and <a href="http://michaelwessely.com/" target="_blank">Michael Wessely</a>.<br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/aradhana-adhikari.jpg" alt="Aradhana Adhikari" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Aradhana Adhikari (UROP):</b>

				I developed an automated evaluation system for the Photo-Chromeleon project. I wrote a program that controlled light sources, a camera system and an openCV image processing system that captured the behavior of photochromic coatings under varying illuminations with visible and ultraviolet light. The system also generated a plot of the captured data using a Matlab library.
				<br> Tools/Programming Languages used: Python, OpenCV, Java
                <br><span style="background:orange">Morais &amp; Rosenblum Best UROP Award</span>
				<br><br>
			</div>

		</div>
<br>




<!--
<h4>10) AR Games for Learning Prototyping Skills (with Dishita)</h4><br>
<b>Topic:</b> AR games have been proven to provide better learning experience for various skills in classrooms. In this project, we develop AR based game interface to teach novices prototyping skills such as laser-cutting, 3D printing, breadboarding and other basic maker-skills. As the learner plays a game, various personalized props get released during the game-play that are designed to improve the learner's prototyping skills. At the end of the project, we expect to run a user-study to assess the learning gain of learners.  <br>
<b>Your job:</b> As a UROP/MEng, you will be working on either hardware (for applications in other domains) or software (for seamless synchronization of sensors and actuators for amateurs). Skills for hardware side application: Rhino3D, prototyping with arduino, basic digital fabrication (lasercutting/3D printing), basic MechE building (using workshop tools, soldering circuits etc) and basic electronics (working with sensors/actuators etc). For Software side application: Unity3D, Vuforia, python, C# or VB Scripting, 3D Rhino, Grasshopper, Blender etc. Interest in games and having worked with Hololens or any other AR/VR device is a plus.  -->



<!-- 		<div class="col-md-2" style="text-align: left;">
				<img src="images/publications/foldtronics/foldtronics.jpg" width="110px">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<span class="publication-authors">
				Junichi Yamaoka, Mustafa Doga Dogan, Katarina Bulovic, Kazuya Saito, Yoshihiro Kawahara, Yasuaki Kakehi, Stefanie Mueller.
				</span>
				</br>
				<span class="publication-title" style="font-weight:bold;">
				FoldTronics: Creating 3D Objects with Integrated Electronics Using Foldable Honeycomb Structures.
				</span>
				</br>
				<span class="publication-proceedings">
				In <i>Proceedings of CHI 2019 (to appear)</i>.
				</span>
				</br>
			</br>
			</div>



			<div class="col-md-2" style="text-align: left;">
				<img src="images/publications/craftsupport/craftsupport.jpg" width="110px">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<span class="publication-authors">
				Martin Nisser, Junyi Zhu, Tianye Chen, Katarina Bulovic, Parinya Punpongsanon, Stefanie Mueller.
				</span>
				</br>
				<span class="publication-title" style="font-weight:bold;">
				Sequential Support: 3D Printing Dissolvable Support Material for Time-Dependent Mechanisms.
				</span>
				</br>
				<span class="publication-proceedings">
				In <i>Proceedings of TEI 2019 (to appear)</i>.
				</span>
				</br>
				<a href="research/sequential-support/sequential-support.html" class="btn btn-homepage" alt="page">Project Page</a>
				</br>
			</br>
			</div>



 -->



	</div>

		<div class="col-md-4" style="text-align: left;">
			<h3 class="headline">Previous UROPs/MEng-es</h3>

			<hr>

			<h3 class="medium-headline">
				<a href="http://xin-wen.me/">Xin Wen (6-3, UROP/SuperUROP/UTA)</a>
			</h3>

			<div class="col-md-12" style="text-align: left;padding-bottom:30px">
				<img src="images/uropmeng/xin-wen.jpg" width="250px" alt="Xin Wen" >
			<p style="text-align:center; margin-top:0px">
				<ul style="padding-left:0px;">
					<li><a href="https://hcie.csail.mit.edu/research/colormod/colormod.html">implemented 3D modeling plugin for research project ColorMod + co-authored ACM CHI 2018 paper</a></li>
					<li>presented ColorMod at ACM CHI conference in Montreal as talk and live demo (3000 attendees)</li>
					<li><a href="https://www.csail.mit.edu/news/changing-color-3-d-printed-objects">ColorMod mentioning Xin covered by BBC, CNN, and was a main spotlight on MIT website</a></li>
					<li><a href="https://www.eecs.mit.edu/news-events/announcements/eecs-celebrates-2018-recognizing-departments-outstanding-contributors">MIT EECS Best UROP Award for her work on ColorMod</a></li>
					<li>path in the lab: UROP summer 2017, SuperUROP fall 2017/spring 2018, <a href="https://hcie.csail.mit.edu/classes/2018-fall-6810/6810-engineering-interactive-technologies.html">UTA for Prof. Mueller's class 6.810 Engineering Interactive Technologies in fall 2018</a></li>
				</ul>
				<img src="images/uropmeng/colormod-demo.jpg" width="350px" alt="Xin Wen" >
				<img src="images/uropmeng/colormod-talk.jpg" width="350px" alt="Xin Wen" >

			</p>
			</div>

			<hr>

			<h3 class="medium-headline">
				Lotta Blumberg (6-1, UROP/MEng/TA)
			</h3>

			<div class="col-md-12" style="text-align: left;">
				<img src="images/uropmeng/lotta-blumberg.jpg" width="350px" alt="Lotta Blumberg" >
			<p style="text-align:center; margin-top:0px">
				<ul style="padding-left:0px;">
					<li>build adaptive hardware prototype using 3D printing & electronics + co-authored Adaptive Learning paper (under submission)</li>
					<li>currently working on two projects with PhD student Junyi Zhu: silicone casting 3D breadboards and corresponding 3D modeling tool + making minutiarized custom PCB boards (to be submitted as two papers to ACM UIST 2019)</li>
					<li>path in the lab: <a href="https://hcie.csail.mit.edu/classes/2018-fall-6810/6810-engineering-interactive-technologies.html">student in Prof. Mueller's class 6.810 Engineering Interactive Technologies in fall 2017)</a>, UROP IAP/spring 2018, MEng starting summer 2018, TA for 6.810 in fall 2018</li>
				</ul>

			</p>
			</div>


			for a list of <a href="https://hcie.csail.mit.edu/people.html">all previous MEng-es and UROPs, please see the team subpage</a>.
<!--

			<div style="margin-bottom:35px">

					<h4 style="font-weight:normal; margin-bottom:10px;"><a href="https://risingstars18-eecs.mit.edu/" target="_blank">MIT EECS Rising Stars Workshop 2018</br></a></h4>
					<a href="https://risingstars18-eecs.mit.edu/" target="_blank"><img src="images/logo/risingstars.jpg" height="170px"></a>
			</div> -->




<!-- 		We are also part of MIT's International Design Center <br><br>
		<a href="http://idc.mit.edu/">
		<img src="images/logo/IDC.jpg" alt="International Design Center" width="200px">
		</a><br><br> -->
	</div>
	</div>


		<!-- News list: end section -->
	</div>
</div>

<div class="dc_clear">
</div>

</br>
</br>
</br>
</br>
</section>

<div class="container">
	<div class="row">
		<div class="col-md-12 footer" style="text-align: center;">
			<span class="copyright">
			Since 2017 &copy; MIT CSAIL (HCI Engineering group) [redesign by
			<a href="http://punpongsanon.info/" target="_blank" style="text-decoration:none; border-bottom:0px">
			moji
			</a>].
			All Rights Reserved.

			<a href="http://mit.edu/" target="_blank" style="text-decoration:none; border-bottom:0px">
			<img src="images/logo/mit.svg" alt="MIT" class="footer-logo" />
			</a>
			<a href="http://csail.mit.edu/" target="_blank" style="text-decoration:none; border-bottom:0px">
			<img src="images/logo/csail.svg" alt="CSAIL" class="footer-logo"/>
			</a>
			<a href="http://hci.csail.mit.edu/" target="_blank" style="text-decoration:none; border-bottom:0px">
			<img src="images/logo/hci.svg" alt="HCI" class="footer-logo"/>
			</a>
			</span>
		</div>
	</div>
</div>

<!-- Bootstrap -->
<script type="text/javascript" src="js/bootstrap.min.js"></script>
<!-- header -->
<script type="text/javascript" src="js/headerstrap.js"></script>
<!-- footer -->
<script type="text/javascript" src="js/footerstrap.js"></script>

</body>
</html>
