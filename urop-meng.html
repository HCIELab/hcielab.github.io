<!DOCTYPE html>
<html>
<head>
	<title>HCI Engineering Group</title>
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

	<!-- CSAIL ICON -->
	<link rel="CSAIL" href="/images/icon/csail.ico" type="image/x-icon" />

	<!-- Bootstrap -->
	<link href="css/bootstrap.css" rel="stylesheet">
	<link href="css/custom-style.css" rel="stylesheet">

	<!-- jQuery -->
	<script type="text/javascript" src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>

	<!-- Google Fonts -->
	<link href="https://fonts.googleapis.com/css?family=Roboto" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Lato" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Abel" rel="stylesheet">
	<link href="https://fonts.googleapis.com/css?family=Barlow" rel="stylesheet">

	<!-- Google Analytic -->
	<script type="text/javascript" src="js/analytics.js"></script>
</head>

<body>
<header class="main_header">
	<!-- to be filled by javascript, see header.html -->
</header>

<section class="main_container">

<div class="container">
	<div class="row" style="padding-bottom:0px;margin-bottom:0px">
	</br>
	</br>
	</br>
	<h3 class="headline">UROP / MEng with us</h3>
	<hr>
	Before applying please read the information below carefully.<br>

	<div class="row" style="padding-bottom:0px;margin-bottom:0px">
	
	

		<div class="col-md-8" style="text-align: left;">
			<h3 class="headline">What do we look for in a UROP / MEng?</h3>
			<hr>
			<ul>
				<li>When getting started in our lab, UROPs / MEng students typically start out by supporting one of our PhD students or postdocs on their research project.</li>
				<li>These research projects will be submitted for publication at the top HCI conferences ACM CHI and ACM UIST with the UROP / MEng-es co-authoring the papers and in some cases also traveling to the conference to give part of the talk or a live demo.</li>
				<li>We only look for UROPs/MEng-es seriously interested in becoming part of our research group. Each research project is important for the career of one of our PhD students or postdocs--we rely on each UROP and MEng to be a reliable team member and committed to making the project a success.</li>
				<li>In turn, you will be a member of a family-style research team with great mentoring, learn many new skills, and have a professional looking project on your portfolio.</li>
				<li>While we love to hear your own project ideas, the standard path in our lab is to first join an on-going research project with a senior mentor (PhD student or postdoc). Identifying a novel research contribution often takes years of training and is even a hard task for a mid-level PhD student.</li>
			</ul>

		<h3 class="headline">UROP: Time Commitment + Pay/Credits</h3>
			<hr>
			<ul>
				<li>UROPs will work ca. 8-10 hours per week. We care about outcomes and do not track your hours. However, we expect everyone to be present in the lab for most of this time to keep the communication paths short.</li>
				<li>You can do your UROP for pay or for credit.</li>
				<li>Please reach out before the following deadlines: spring semester: February 1, summer semester: April 1, fall semester: September 1, IAP: December 1).</li>
				<li>What if I don't have the skills yet? We do not expect you to already know everything--if you love the project and you are willing to put in the energy and time, we will be happy to teach you the necessary skills.</li>
			</ul>

		<h3 class="headline">MEng: Time Commitment + Pay</h3>
			<hr>
			<ul>
				<li>MEng-es are expected to spend at least 20 hours per week on their project. We care about outcomes and do not track your hours. However, we expect everyone to be present in the lab for most of this time to keep the communication paths short.</li>
				<li>You can do 2-, 3-, or 4-semester MEng-Thesis projects.</li>
				<li>Before applying to the lab, you need to have secured a TA position since we don't have funding to support MEng students (please mention the TA position in your email).</li>
			</ul>

		<h3 class="headline">Application Process</h3>
			<hr>
			If you are interested in working with us, send Prof. Mueller an email with the following:
			<ul>
				<li>what position you are interested in (UROP/MEng)</li>
				<li>when you would like to start</li>
				<li>your CV</li>
				<li>a website showing your previous projects or a project portfolio as pdf</li>
				<li>your latest grade transcript</li>
				<li>two names of people who we can ask for a short recommendation (e.g., previous UROP or internship mentors)</li>
			</ul>

			Prof. Mueller will then forward your materials to her PhD students and Postdocs who will then get back to you in case they have an opening. To get an idea of the type of projects our UROPs and MEng-es work on, you can read more below or go to the publication list on our homepage.<br><br>
			<!-- // the PhD student or postdoc you want to work with (see project descriptions and contact information below) -->


<!-- 		<h3 class="headline">Current Topics</h3>
			<hr>
			All of our project openings are posted on the UROP portal. <br>
			Note that this does not mean they are only for UROPs , MEng-es can also reach out to us for those projects.<br><br> -->
<!--
			<b>Current UROP/MEng Openings:</b>
			<ul>
				 <li><a href="https://urop.mit.edu/content/slicehub-ecosystem-re-using-exploring-and-sharing-slicing-results">SliceHub: An Ecosystem for Re-using, Exploring, and Sharing of Slicing Results</a></li> -->
				<!-- <li><a href="https://urop.mit.edu/content/3d-sensors-rapid-prototyping">3D Sensors for Rapid Prototyping</a> -->
				<!-- <li><a href="https://urop.mit.edu/content/making-machine-makes-machines">Making a Machine that Makes Machines</a></li>
			</ul>
-->


		<h3 class="headline">Previous Projects</h3>
		<hr>
		Below you find a summary of projects that resulted in published research papers with UROPs and MEng-es co-authoring the papers.<br><br>
            
            <div class="col-md-2" style="text-align: left;">
			<div href="research/style2fab/style2fab.html"><img src="research/thermochromorph/images/teaser.png" width="110px"></div>
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				<div href="research/style2fab/style2fab.html">Thermochromorph (ACM SIGGRAPH Asia 2024 Art Paper)</div>
			</div>
			This project was led by HCIE <a href="https://www.tichamelody.com/">PhD student Ticha Sethapakdi.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/juliana-covarrubias.jpeg" alt="Juliana Covarrubias" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Juliana Covarrubias (UROP) :</b>
				During the early stages of the project, Juliana made a number of thermochromic prints to explore the expressiveness and limitations of the printmaking approach. She additionally contributed to the project's conceptual development by researching the history of printmaking and critically examining how Thermochromorph prints fit within that context.
				<br> Tools/Programming Languages used: Processing, Wet Lab Tools.
				<br><br>
			</div>
			
		</div>

		<div class="col-md-2" style="text-align: left;">
			<div href="research/style2fab/style2fab.html"><img src="research/portachrome/images/portachrome-icon.png" width="110px"></div>
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				<div href="research/style2fab/style2fab.html">PortaChrome (ACM UIST 2024 Paper)</div>
			</div>
			This project was led by HCIE <a href="https://yunyi-zhu.github.io/">PhD student Yunyi Zhu.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/angelina-j-zheng.jpg" alt="Angelina J. Zheng" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Angelina J. Zheng (UROP) :</b>
					Angelina performed early experiements on incorporating photochromic materials in silicone, laser-cut and soldered patches of custom electronics and ran technical evaluations on the color-changing process with the final electronics.  
				<br> Tools/Programming Languages used: Arduino, Electronics, Wet Lab Tools.
				<br><br>
			</div>
			
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/kyle-heinz.jpg" alt="Kyle Heinz" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Kyle Heinz (UROP) :</b>
					Kyle characterized the fiber laser cutter in the lab and developed a set of parameters for laser cutting copper foil, polyimide tape and resin tape to prototype custom multi-layer flexible circuits. Kyle also fabricated patches of electronics and helped develop the control board code that involves bluetooth transmission of the color array. 
				<br> Tools/Programming Languages used: Arduino, Fiber laser cutter, Electronics.
				<br><br>
			</div>

			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/grace-tang.jpg" alt="Grace Tang" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Grace Tang (UROP) :</b>
					Grace implemented a script that generates the traces for the RGB and UV LEDs with given input of number of LEDs and distance between two LEDs. Grace also prototyped ways to integrate thin flex-PCB in knitted objects to use as a fiber. 
				<br> Tools/Programming Languages used: Javascript, Electronics, Knitting.
				<br><br>
			</div>

			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/luca-musk.jpg" alt="Luca Musk" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Luca Musk (UROP) :</b>
					Luca built a characterization system for the PortaChrome device, which involves controlling a DSLR, an LED ring and the PortaChrome device to desaturate and take a picture every five seconds. 
				<br> Tools/Programming Languages used: Arduino.
				<br><br>
			</div>
		</div>


		<div class="col-md-2" style="text-align: left;">
			<a href="research/style2fab/style2fab.html"><img src="research/style2fab/images/style2fab-icon.png" width="110px"></a>
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				<a href="research/style2fab/style2fab.html">Style2Fab (ACM UIST 2023 Paper)</a>
			</div>
			This project was led by HCIE <a href="http://www.farazfaruqi.com/">PhD student Faraz Faruqi.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/leandra-tejedor.png" alt="Leandra Tejedor" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Leandra Tejedor (MEng) :</b>
					Leandra managed running the user study, collecting the data from the users, and performing the analysis. She also helped in designing the user interface for the project, and contributed to the generative AI model used in the proejct.
				<br> Tools/Programming Languages used: Python, Blender, Blender Python API.
				<br><br>
			</div>
			
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/ahmed-katary.jpg" alt="Ahmed Katary" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Ahmed Katary (UROP) :</b>
					Ahmed developed the segmentation algorithm used in the project to separate aesthetic and functional parts in the 3D model. He also collaborated in changing the generative AI model to do selective stylization of 3D models instead of global stylization. Ahmed also collaborated in developing the Blender plugin used as the UI for Style2Fab. 
				<br> Tools/Programming Languages used: Generative AI, Python, Blender, Blender Python API.
				<br><br>
			</div>

			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/tarik-hasic.jpg" alt="Tarik Hasic" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Tarik Hasic (UROP) :</b>
					Tarik collaborated in developing the assembly algorithm to match different segments in 3D models, and also developed part of the UI for Style2Fab using the Blender API. Tarik also helped in the formative study for the project, and the data collection for training the machine learning classifier.  
				<br> Tools/Programming Languages used: Python, Blender, Blender Python API.
				<br><br>
			</div>

			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/nayeemur-rahman.jpg" alt="Nayeemur Rahman" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Nayeemur Rahman (UROP) :</b>
					Nayeemur collaborated in developing the assembly algorithm to match different segments in 3D models, and the data collection for training the machine learning classifier. He also collaborated on developing the segmentation algorithm for the project. 

				<br> Tools/Programming Languages used: Python, Blender.
				<br><br>
			</div>




		</div>

		<div class="col-md-2" style="text-align: left;">
			<a href="research/brightmarker/images/brightmarker-icon.png"><img src="research/brightmarker/images/brightmarker-icon.png" width="110px"></a>
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				<a href="research/brightmarker/brightmarker.html">BrightMarker (ACM UIST 2023 Paper)</a>
			</div>
			This project was led by HCIE <a href="http://www.dogadogan.com/">PhD student Doga Dogan.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/patrick-haertel.jpg" alt="Patrick Haertel" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Patrick Haertel (UROP):</b>
				I experimented with different 3D printing filaments and techniques to determine how they interacted with the unique fluorescent filament we were using. Once I had found the optimal filaments and techniques to use with the fluorescent filament, I designed and printed objects with hidden markers embedded beneath the surface in collaboration with Jamie. I also worked with Raul and Doga to tune an OpenCV python program which we used for detecting the codes.
				<br> Tools/Programming Languages used: Ultimaker Cura, Python (OpenCV), Blender
				<br><br>
			</div>
            <div class="col-md-15" style="text-align: left;">
				<img src="images/people/jamison-okeefe.jpg" alt="Jamison O'Keefe" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Jamison O'Keefe (UROP):</b>
				I developed a plugin which takes a 3D model and embeds ArUco markers, or codes uploaded by the user, and produces the STL files needed to print the object with embedded BrightMarkers. The markers are embedded optimally based on desired marker size, number, visibility, etc. I also built the AR speaker application, and contributed to other applications. 
				<br> Tools/Programming Languages used: Python, Blender, Blender Python API, Unity, Hololens, Meta Quest.
				<br><br>
			</div>
		</div>
		
		<div class="col-md-2" style="text-align: left;">
			<img src="research/structcode/images/structcode-thumbnail.png" width="110px">
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				StructCode (ACM SCF 2023 Paper)
			</div>
			This project was led by HCIE <a href="https://www.dogadogan.com/">PhD student Mustafa Doga Dogan.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/richard-qi.jpg" alt="Richard Qi" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Richard Qi (UROP):</b> Richard designed and implemented efficient and accurate computer vision algorithms using OpenCV to decode embedded Structcodes within living hinges and finger joints. <br>
				Tools/Programming languages: OpenCV, C++. <br>
				<br>
			</div>
		</div>
		
        	<div class="col-md-2" style="text-align: left;">
			<img src="research/polagons/images/polagons-icon.png" width="110px">
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				Polagons (ACM CHI 2023 Paper)
			</div>
			This project was led by HCIE <a href="http://www.tichamelody.com/">PhD student Ticha Sethapakdi.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/laura-huang.jpg" alt="Laura Huang" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Laura Huang (UROP):</b> Laura built the design tool for Polagons. This involved implementing the mathematical model for the color-changing effects in Python and developing the user interface in Processing. <br>
				Tools/Programming languages: Processing, Python. <br>
				<br>
			</div>
		</div>


		<div class="col-md-2" style="text-align: left;">
			<img src="research/institches/images/institches-thumbnail.png" width="110px">
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				InStitches (ACM CHI 2023 Paper)
			</div>
			This project was led by HCIE <a href="http://www.mackenzieleake.com/">Postdoc Mackenzie Leake.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/kathryn-jin.jpg" alt="Kathryn Jin" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Kathryn Jin (UROP):</b> Kathryn designed and built the UI and helped recruit participants and run the user study for InStitches. <br>
				Tools/Programming languages: React, Node.js, Python. <br>
				<br>
			</div>
		</div>


		<div class="col-md-2" style="text-align: left;">
			<img src="research/musclerehab/images/musclerehab-thumbnail-no-caption.png" width="110px">
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				MuscleRehab (ACM UIST 2022 Paper)
			</div>
			This project was led by HCIE <a href="https://www.junyizhu.com/">PhD student Junyi Zhu.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/yuxuan-lei.jpg" alt="Jackson Snowden" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Yuxuan Lei (MEng):</b> Yuxuan designed the Virtual Reality physcial rehablitation environment and built the muscle skeleton avatar for MuscleRehab system. She also worked on communication pipe between Unity and Matlab, user study deployment, Optitrack rig to avatar mapping, and collected data analysis over motion and eye tracking data. <br>
				Tools/Programming languages: Unity, Rhino. <br>
				<br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/aashini-shah.png" alt="Joshua Verdejo" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Aashini Shah (UROP):</b> Aashini worked on user study design and deployment, system deployment with physical therapists. She also worked on post-study data analysis, as well as EIT 3D image recontruction, custom injecting & measuring pattern building and EIT data evaluation over different users across BMI levels. <br>
				Tools/Programming languages: Arduino, C, Matlab. <br>
				<br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/gila-schein.png" alt="Emily Chen" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Gila Schein (UROP):</b> Gila worked on EIT sensing board script development, especially the wireless communication part of the system. She also contributed to user study setup and deployment, different EIT image reconstruction algorithms evaluation, and formative user study interviews. <br> 
				Tools/Programming languages: Arduino, C, Matlab. <br>
				<br><br>
			</div>
		</div>
		

		<div class="col-md-2" style="text-align: left;">
			<img src="research/mixels/images/mixel-screenshot.png" width="110px">
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				Mixels (ACM UIST 2022 Paper)
			</div>
			This project was led by HCIE <a href="http://martinnisser.org">PhD candidate Martin Nisser.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/yashaswini-makaram.jpg" alt="Yashaswini Makaram" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Yashaswini Makaram (UROP):</b> Yashaswini worked on programming a magnetic plotter to rapidly print North- and South-aligned magnetic poles onto ferromagnetic sheet. This involved synthesizing magnetic signatures as binary-valued 2D matrices, and writing a script that translated these matrices into gcode for plotting using the magnetic plotter. She worked with team members to develop several iterations of prototypes to this end, ultimately building a device that could program custom magnetic signatures efficiently and accurately. <br>Tools/Programming Languages used: Python, Electronics, Rapid Prototyping.<br><br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/lucian-covarrubias.jpg" alt="Lucian Covarrubias" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Lucian Covarrubias (UROP):</b> Lucian worked on building a magnetic plotter capable of rapidly printing magnetic signatures onto ferromagnetic sheet. This plotter took the form of a modular hardware add-on that could be affixed onto a 3-axis CNC to be operated; in his case, a 3D printer. He prototyped several iterations of prototypes to this end, ultimately building a device that could program custom magnetic signatures efficiently and accurately. <br>Tools/Programming Languages used: CAD, Solidworks, Rapid Prototyping.<br><br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/amadou-bah.jpg" alt="Amadou Bah" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Amadou Bah (MEng):</b> Amadou developed a custom electromagnetic end-effector that could be used to program ferromagnetic sheet. He measured and characterized the magnetic properties of a variety of materials in terms of coercivity, remanence and saturation, and showed how to design both the programming and programmed materials for optimal effect. Finally, he built a custom-shaped electromagnetic tip and showed how this could program ferromagnetic material with locally strong, high-resolution magnetic pixels. <br>Tools/Programming Languages used: CAD, Solidworks, Rapid Prototyping.<br><br>
			</div>
        </div>



		<div class="col-md-2" style="text-align: left;">
			<img src="research/sensorviz/images/sensorviz-thumbnail.png" width="110px">
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				SensorViz (ACM DIS 2022 Paper)
			</div>
			This project was led by HCIE <a href="https://www.yoonji-kim.com/">Postdoc Yoonji Kim.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/mihir-trivedi.jpg" alt="Mihir Trivedi" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Mihir Trivedi (MEng):</b> I worked with the SensorViz team to develop the AR (augmented reality) components of SensorViz, as well as specific visualizations of individual sensors in 3D space. Using Rhino, Python, and experience with iOS app development, we utilized libraries and wrote software to visualize the sensors represented in our paper in an augmented reality environment. This allows the end user to get a feel for the size, shape, and placement of multiple sensors in a real environment without needing to purchase an array of similar devices. <br>Tools/Programming Languages used: Python, Rhino Grasshopper, Swift.<br><br>
			</div>
        </div>

        <div class="col-md-2" style="text-align: left;">
			<img src="research/kinecam/images/kinecam-thumbnail.png" width="110px">
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				KineCAM (ACM SIGGRAPH 2022 Art Paper)
			</div>
			This project was led by HCIE <a href="http://tichamelody.com/">PhD student Ticha Sethapakdi.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/miranda-cai.jpg" alt="Miranda Cai" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Miranda Cai (UROP):</b> I designed the circuitry and hardware pipeline for this project. I also developed the software behind the hardware components and helped with integrating our image processing techniques onto the system. <br>Tools/Programming Languages used: Python, Raspberry Pi.<br><br>
			</div>
            <div class="col-md-15" style="text-align: left;">
				<img src="images/people/catalina-rodriguez.png" alt="Catalina Rodriguez" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Catalina Monsalve Rodriguez (UROP):</b> I was responsible for all the image processing components of the project. To do this, I wrote software that converts the video frames into an interlaced image. The interlaced image was constructed in such a way that it animates when placed under a sliding striped overlay. <br>Tools/Programming Languages used: Python, Raspberry Pi.<br><br>
			</div>
        </div>
            
		<div class="col-md-2" style="text-align: left;">
			<a href="research/Electrovoxel/electrovoxel.html"><img src="research/Electrovoxel/images/icra-2.PNG" width="110px"></a>
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				<a href="research/Electrovoxel/electrovoxel.html">ElectroVoxel (IEEE ICRA 2022 Paper)</a>
			</div>
			This project was led by HCIE <a href="http://www.martinnisser.org/">PhD student Martin Nisser.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/yashaswini-makaram.jpg" alt="Yasha" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Yashaswini Makaram (UROP):</b>
				I worked to develop modular robots that maneuvered using electromagnets. I have also been working on a project to stochastically assemble configurations using programmable magnets. Both of these projects require a lot of interdisciplinary work. I needed to pull together knowledge from physics, mathematics, and electrical engineering in order to find solutions. Along the way I had to discover not only the solutions to unanswered questions, but also had to contend with questions that had not been asked in the first place. From this Research opportunity, I realised how deep and broad  research can be and how to contend with unexpected results. 
				<br> Tools/Programming Languages used: Python, Electronics, Rapid Prototyping
				<br><br>
			</div> 
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/leon-cheng.jpg" alt="Leon Cheng" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Leon Cheng (MEng):</b>
				I designed and developed a 3D interactive simulation for the project's focus on magnetic cube block assembly. Reconfigurations of multiple Electrovoxel cubes are difficult to coordinate because every cube's set of magnets is reoriented with a rotation in space and adjacent magnets must be carefully coordinated to produce the correct strength and duration of magnetic attraction or repulsion. Therefore, building a Javascript to Arduino program that can simulate the physics and follow UX heuristics was able to vitally simplify the level of thinking required for large reconfigurations. I also supported the mechanical assembly of physical cubes using custom wrapped electromagnets for the specially designed physical cube. 
				<br> Tools/Programming Languages used: React, ThreeJS, TypeScript, Arduino.
				<br><br>
			</div> 
		</div>

		<div class="col-md-2" style="text-align: left;">
			<a href="research/infraredtags/infraredtags.html"><img src="research/infraredtags/infraredtags-thumbnail.png" width="110px"></a>
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				<a href="research/infraredtags/infraredtags-thumbnail.png">InfraredTags (ACM CHI 2022 Paper)</a>
			</div>
			This project was led by HCIE <a href="http://www.dogadogan.com/">PhD student Doga Dogan.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/ahmad-taka.jpg" alt="Ahmad Taka" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Ahmad Taka (UROP):</b>
				I developed a 3D editor that can take STL files and embed Unique Identifying tags. I also implemented the image processing pipeline for processing the IR codes. I also built various models and tools for InfraredTags applications, including a USB camera module for detection and decoding. 
				<br> Tools/Programming Languages used: Python, OpenCV, Rhino/Grasshopper, Javascript
				<br><br>
			</div>
		</div>
		<div class="col-md-2" style="text-align: left;">
			<img src="research/eit-kit/images/eitkit-thumbnail.jpg" width="110px">
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				EIT-kit (ACM UIST 2021 Paper)
			</div>
			This project was led by HCIE <a href="https://www.junyizhu.com/">PhD student Junyi Zhu.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/jackson-snowden.jpg" alt="Jackson Snowden" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Jackson Snowden (UROP):</b> I developed the EIT-kit sensing board that supports different EIT measurement setups (2- and 4-terminal, up to 64 electrodes, and single or multiple electrode arrays), and that provides adjustable AC injecting current to improve the quality of the signal.
				I also performed evaluations on the electrode contact and measuring data collection.<br>
				Tools/Programming languages: EAGLE, Arduino, C, Matlab. <br>
				<br><br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/joshua-verdejo.png" alt="Joshua Verdejo" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Joshua Verdejo (MEng):</b> I developed an image reconstruction library for mobile devices for interpolating and visualizing the measured data. The library takes EIT measuring data via Bluetooth, and can visualize the reconstructed image in 2D and 3D, as well as AR environment. The library is implemented in Xcode and  designed for iOS devices (e.g. iPhone, iPad). <br>
				Tools/Programming languages: Xcode, Swift, Python. <br>
				<br><br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/emily-chen.jpeg" alt="Emily Chen" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Emily Chen (UROP):</b> I developed a microcontroller library for EIT sensing board that automates the calibration of the signals and facilitates data collection. The library collects the EIT measuring data and send them either via Serial Port or Bluetooth (to mobile image reconstruction library). The library supports both ESP32 and Teensy as the microcontroller.<br> 
				Tools/Programming languages: Arduino, C, Matlab. <br>
				<br><br>
			</div>
		</div>

		<div class="col-md-2" style="text-align: left;">
			<img src="research/sensicut/images/sensicut-thumbnail.jpg" width="110px">
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				SensiCut (ACM UIST 2021 Paper)
			</div>
			This project was led by HCIE <a href="https://www.dogadogan.com/">PhD Student M. Doga Dogan.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/steven-acevedo.jpg" alt="Steven Acevedo" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Steven Acevedo (UROP):</b> Steven worked on multiple aspects of the project: First, he developed and tested machine learning models (involving convolutional neural networks) to predict laser cutting sheets' material type from a single
speckle pattern. Second, he helped develop a Web-based user interface (HTML, JS, and CSS) for creating a novel, material-aware laser cutting workflow. Third, he developed 3D models for mounting speckle imaging hardware onto laser cutters using CAD software. He is a co-author on the UIST'21 paper "SensiCut: Material-Aware Laser Cutting Using Speckle Sensing".
				<br><br>
			</div>
		</div>

		<div class="col-md-2" style="text-align: left;">
			<img src="research/metasense/images/metasense-thumbnail.jpg" width="110px">
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				MetaSense (ACM UIST 2021 Paper)
			</div>
			This project was led by HCIE <a href="https://www.jungong.me/">Visiting PhD Student Jun Gong.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/olivia-seow.jpg" alt="Olivia Seow" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Olivia Seow (SM):</b> MetaSense integrates sensing into 3D printable metamaterial structures by fabricating specific cell walls from conductive filament, thereby creating capacitive sensors. Olivia worked on and improved the web-based editor to create these structures. She developed the algorithm for analyzing deformations in the cell structures, in order to identify most optimal locations for placing conductive cell walls during the design phase. She prototyped the algorithm in a standalone three.js environment, and integrated it on the editor with Karamba, a finite element solver in Grasshopper. Using this editor, she designed and 3D printed mechanisms to showcase Metasense and its integrated sensing capabilities, experimenting with and identifying 3D printer specifications for fabricating robust structures. She helped to visualize the capacitances of the cell structures to characterize their performance. She was involved with the whole research process, creating figures, videos, and writing for the publication as co-first author.
				<br><br>
			</div>
		</div>

		<div class="col-md-2" style="text-align: left;">
			<img src="research/lenticularobject/images/lenticularobject-thumbnail.jpg" width="110px">
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				Lenticular Object (ACM UIST 2021 Paper)
			</div>
			This project was led by HCIE <a href="http://yunyizhu.info/">PhD student Yunyi Zhu.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/yunyi-zhu.jpg" alt="Yunyi Zhu" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Yunyi Zhu (MEng):</b> I developed the Lenticular Object interactive editor that allows the user to upload an arbitrary 3D model and
				specify the appearances to show at each viewpoint.
				I implemented the algorithm that generates the corresponding Lenticular Object according to the user input.
				I also performed evaluations on the performance of the fabrication method and fabricated four application scenarios.
				Tools/Programming languages: Rhino 3D, Grasshopper, Python, C#. <br>
				<span style="background:orange">MIT EECS Licklider UROP Award 2019</span>
				<br><br>
			</div>
		</div>

		<div class="col-md-2" style="text-align: left;">
			<a href="https://hcie.csail.mit.edu/research/laserfactory/laserfactory.html"><img src="research/laserfactory/images/laserfactory-thumbnail2.png" width="110px"></a>
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				<a href="https://hcie.csail.mit.edu/research/laserfactory/laserfactory.html">LaserFactory (ACM CHI 2021 Paper)</a>
			</div>
		This project was led by HCIE <a href="http://martinnisser.org/">PhD student Martin Nisser.</a><br><br>
		<div class="col-md-15" style="text-align: left;">
			<img src="images/people/christina-liao.jpg" alt="christina Liao" class="img-urop img-rounded">
		</div>
		<div class="col-md-10" style="text-align: left;">
			<b>Christina Liao (MEng):</b> Christina developed the software pipeline for a novel fabrication method that uses a laser cutter to automatically create fully-functional devices that work immediately after fabrication is complete. The software pipeline she designed consists of a design interface, in which users can define the circuitry and geometry of the device to fabricate, and a post-processing system that transforms the design into machine instructions that a laser cutter uses to fabricate the device. With this pipeline, users can design and fabricate high-fidelity devices without needing to know the specifics behind the fabrication process. <br>

							Tools/Programming languages: Javascript, Python, Blender, Adobe Illustrator.<div style="background:orange">2021 Charles & Jennifer Johnson Best Computer Science MEng Thesis Award</div><br><br>
		</div>
		<div class="col-md-15" style="text-align: left;">
			<img src="images/people/aradhana-adhikari.jpg" alt="aradhana adhikari" class="img-urop img-rounded">
		</div>
		<div class="col-md-10" style="text-align: left;">
			<b>Aradhana Adhikari (MEng):</b> Ara developed a 3D visualization tool in Blender for LaserFactory's fabrication system. The 3D visualization tool is a two part system. One part generates 3D models of the fabrication output from 2D SVG design files. In addition to the 3D model, the tool also creates an animated visualization of all the fabrication steps involved in creating the design, which includes all steps for creating the geometry of the design as well as the steps for building th electronic circuit. These 3D models and animations are created using Blender’s Python API, and the results are displayed in a Blender window. This tool is used to visualize designs with many different features, including LED and quadrotor control circuits, structures with holes, and also 3D structures created through folding. <br>

							Tools/Programming languages: Python, Blender.<br><br>
		</div>
		</div>



        <div class="col-md-2" style="text-align: left;">
			<a href="https://hcie.csail.mit.edu/research/fabricaide/fabricaide.html"><img src="research/fabricaide/images/fabricaide-thumbnail2.png" width="110px"></a>
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				<a href="https://hcie.csail.mit.edu/research/fabricaide/fabricaide.html">Fabricaide (ACM CHI 2021 Paper)</a>
			</div>
			This project was led by HCIE <a href="http://tichamelody.com/">PhD student Ticha Sethapakdi.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/adrian-sy.jpg" alt="Adrian Sy" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Adrian Sy (MEng):</b> I implemented a fast 2D packing algorithm that packs parts of a laser-cut design onto material sheets that may have previously cut holes. The algorithm produces comparable-quality solutions 4 times faster than Deepnest, a state-of-the-art open-source nesting tool. I also built the Docker image to make Fabricaide easier to install onto participants' machines for the remote user study. <br>

                Tools/Programming languages: C++, Python, Docker.<br><br>
			</div>
        </div>

        <div class="col-md-2" style="text-align: left;">
			<a href="https://hcie.csail.mit.edu/research/chromoupdate/chromoupdate.html"><img src="research/chromoupdate/images/chromoupdate-thumbnail.png" width="110px"></a>
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				<a href="https://hcie.csail.mit.edu/research/chromoupdate/chromoupdate.html">ChromoUpdate (ACM CHI 2021 Paper)</a>
			</div>
			This project was led by HCIE <a href="http://michaelwessely.com/">Postdoc Michael Wessely.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/cattalyya-nuengsigkapian.jpg" alt="Cattalyya Nuengsigkapian" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Cattalyya Nuengsigkapian (MEng):</b> I developed a multithreaded optimization algorithm for reprogramming multi-color textures, which reduces the reprogramming time by half compared to previous work (PhotoChromeleon). I implemented multi-round optimization for better color quality and supported digital previews of the resulting pattern on a Blender 3D model.
                I implemented a light controller and camera capture in Python to automatically collect and generate an activation and deactivation graph of dye color changes over time in MATLAB.<br>

                Programming languages: Processing(Java), Python, MATLAB.<br><br>
			</div>
        </div>

        <div class="col-md-2" style="text-align: left;">
			<a href="https://hcie.csail.mit.edu/research/fabo/fabo.html"><img src="research/fabo/images/fig0-Thumbnail4.png" width="110px"></a>
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				<a href="https://hcie.csail.mit.edu/research/fabo/fabo.html">FabO (ACM C&C 2021 Paper)</a>
			</div>
			This project was led by HCIE <a href="https://www.dishitaturakhia.com/">PhD student Dishita Turakhia.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/harrison-allen.jpeg" alt="Harrison Allen" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Harrison Allen (UROP):</b> Harrison devdeloped the user interface for the FabO toolkit. He was part of the team from the early conception of the project and worked on several stages of the research project from brainstorming system designs, to developing prototypes in AR, VR, and desktop games. He also worked on fabricating some of the physical protoypes of the objects from the games. For the final version of the system, Harrison developed the interface in PyQt and used OpenCv library for the computer vision based features. Tools/Programming Languages: Rhino3D, Unity, Microsoft Hololens, Python, laser cutter.  </span>
				</br><br>
			</div>
		</div>

        <div class="col-md-2" style="text-align: left;">
			<a href="https://hcie.csail.mit.edu/research/adapt2learn/adapt2learn.html"><img src="research/adapt2learn/images/fig0-Thumbnail.png" width="110px"></a>
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				<a href="https://hcie.csail.mit.edu/research/adapt2learn/adapt2learn.html">Adapt2Learn (ACM TEI and DIS 2021 Papers)</a>
			</div>
			This project was led by HCIE <a href="https://www.dishitaturakhia.com/">PhD student Dishita Turakhia.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/yini-qi.jpg" alt="Yini Qi" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Yini Qi (MEng):</b> Yini joined the project from its conception and assited in brainstorming the system design, application examples, and prototype design. She also built two prototypes of the adaptive tools - an adaptive bike and adaptive pen grips. The fabrication of the adaptive bike involved installing sensors, actuators, and additional electronics on the bike. Prototyping the pen grips involved implemntation of computer vision techniques for handwriting recognition. Finally, Yini also assisted in conducting user studies to evaluate the system design. Tools/Programming Languages: Protoyping with electronics, Python, Arduino, lasercutting, 3D printing.  </span>
				</br><br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/andrew-wong.jpg" alt="Andrew Wong" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Andrew Wong (UROP):</b> Andrew developed the web-based user interface for the Adapt2Learn toolkit. Besides working on the design of the interface, he also added several additional features, such as modifying sensor settings, actuator settings and mapping those settings to autogenerate a learning algorithm as an output.This involved using index.html, main.css, and ui.js to design the web based interface that automatically generates the microcontroller script. Tools/Programming Languages: HTML, CSS, Javascript, Python, Arduino.  </span>
				</br><br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/Lotta-Blumberg.jpg" alt="Lotta Gili-Blumberg" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Lotta Gili-Blumberg (UROP):</b> Lotta designed and fabricated the adaptive basketball stand ptotype which was mounted with several sensors and actuator motors. She also assisted in conducting the user studies. Tools/Programming Languages used: Rhino 3D, protoyping with electronics, fabrication in metal and wood workshop using advanced tools, Python, Arduino, lasercutting, 3D printing
				</br><br>
			</div>
		</div>

		

		<div class="col-md-2" style="text-align: left;">
			<a href="https://hcie.csail.mit.edu/research/morphsensor/morphsensor.html"><img src="research/morphsensor/morphsensor-thumbnail-image.png" width="110px"></a>
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				<a href="https://hcie.csail.mit.edu/research/morphsensor/morphsensor.html">MorphSensor (ACM UIST 2020 Paper)</a>
			</div>
			This project was led by HCIE <a href="https://www.junyizhu.com/">PhD student Junyi Zhu.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/yunyi-zhu.jpg" alt="Yunyi Zhu" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Yunyi Zhu (SuperUROP):</b> I developed the MorphSensor 3D editor that can load existing sensor modules, rearrange their components on the 3D prototype object, and export the design for fabrication. I also built various initial breadboard circuits for MorphSensor applications, including N95 mask, blue light monitoring glasses etc. Tools/Programming Languages used: Rhino 3D, Python, Arduino, C. <br> <span style="background:orange">MIT EECS Best SuperUROP Award 2019</span>
				</br><br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/jiaming-cui.jpg" alt="Jiaming Cui" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Jiaming Cui (UROP):</b> I developed the sensor module database for the MorphSensor system. I also built initial versions of MorphSensor via kapton tapes, laser cutter and copper wire sewing. I designed the final MorphSensor footprints (the Bigfoot) in EAGLE, and implemented the Bigfoot auto-generation on unrecorded SMD footprints via EAGLE ULP. Tools/Programming Languages used: Rhino 3D, Python, EAGLE ULP, laser cutter.
				</br><br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/leon-cheng.jpg" alt="Leon Cheng" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Leon Cheng (UROP):</b> I developed an algorithm embedded within MorphSensor system that automatically places electronic components from EAGLE sensor module file in a valid layout onto a custom-formed board. I worked on generating initial fabrication guide files for exported sensor modules from MorphSensor system. I also worked on extracting logic wire connections from EAGLE files as json files for MorphSensor system. Tools/Programming Languages used: Rhino 3D, Python, EAGLE
				</br><br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/jackson-snowden.jpg" alt="Jackson Snowden" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Jackson Snowden (UROP):</b> I designed the initial footprints (BigFoot) used in the project and later verified these designs after receiving the fabricated boards. Tools/Programming Languages used: KiCAD, EAGLE.
				</br><br></br><br>
			</div>
		</div>


		<div class="col-md-2" style="text-align: left;">
			<a href="research/sprayableuserinterfaces/main.html"><img src="research/sprayableuserinterfaces/sprayableuserinterfaces-thumbnail.png" width="110px"></a>
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				<a href="research/sprayableuserinterfaces/main.html">Sprayable User Interfaces (ACM CHI 2020 Paper)</a>
			</div>
			This project was led by HCIE <a href="http://michaelwessely.com/">Postdoc Michael Wessely.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/carlos-lozada.jpg" alt="Carlos Castillo Lozada" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Carlos Castillo (UROP):</b> This project included an end-to-end fabrication pipeline from a digital design tool to the fabrication of large UIs using airbrush spraying. I implemented the digital design toolkit in the 3D editor Blender. I implemented a set of tools for touch sensors, sliders, proximity sensors and electroluminescent displays that lets users draw them on a 3D object. The full design can be exported as 2d stencils and as 3D projections. Tools/Programming Languages used: Python(Blender), Processing(Java). <span style="background:orange">MIT EECS Licklider Best UROP Award 2020</span><br><br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/jackson-snowden.jpg" alt="Jackson Snowden" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Jackson Snowden (UROP):</b> I created a capacitive touch sensing driver on an Arduino platform for sensing interactions with sprayed-on contacts. Then, touch inputs were used to drive Philips Hue lights using a custom Python script and to play audio using an Arduino-SD card interface.
    			I also created a touch display driver by utilizing a switching circuit to deliver power to an electroluminescent display while receiving touch input from the same display. This required me to design and fabricate a custom circuit as well as write extensive Arduino software to drive the circuit. Later, I adapted the existing touch sensing driver to do proximity sensing. This involved several filtering techniques to attain maximum sensitivity while rejecting 60 Hz noise from the surroundings. This new software was used to detect swipe gestures and control a photo album. Tools/Programming Languages used: This project primarily required me to use low-level C to get high performance from the Arduino. I was also able to prototype some simple circuits, create a multi-layer PCB design, and fabricate the final PCB by hand.
				</br><br>
			</div>
		</div>


		<div class="col-md-2" style="text-align: left;">
			<a href="research/curveboard/curveboard.html"><img src="research/curveboard/curveboard-thumbnail.jpg" width="110px"></a>
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				<a href="research/curveboard/curveboard.html">CurveBoard (ACM CHI 2020 Paper)</a>
			</div>
			This project was led by HCIE <a href="https://www.junyizhu.com/">PhD student Junyi Zhu.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/Lotta-Blumberg.jpg" alt="Lotta Blumberg" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Lotta Blumberg (MEng):</b> Explored various fabrication methods for CurveBoards and finalized the 3D printing + conductive silicone mixing & injection fabrication pipeline. Fabricated various CurveBoard models, including bracelet, helmet, headphones, frisbee etc. Evaluated the conductivity & durability of the conductive silicone, and evaluated the fabricated CurveBoards via a user study. Tools/Programming Languages used: 3D printer, conductive inkjet printing, conductive silicone, Arduino, C.
				<br><br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/yunyi-zhu.jpg" alt="Yunyi Zhu" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Yunyi Zhu (SuperUROP):</b> I developed the CurveBoard interactive 3D editor that converts an arbitrary geometry into a CurveBoard model. This includes the algorithm of auto-generating bus channels, the UI for adding and deleting channels, as well as performance engineering for converting the channel information into the final CurveBoard 3D model. I also designed various CurveBoard models, including navigation helmet, interactive headphones, frisbee. Tools/Programming Languages used: Rhino3D. <br><span style="background:orange">MIT EECS Best SuperUROP Award 2019</span>
				</br><br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/xin-wen.jpg" alt="Xin Wen" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Xin Wen (UROP):</b> Xin helped out the last couple of weeks building examples. Xin built an interactive CurveBoard navigation helmet for cyclists. The helmet indicates the routing direction via vibration buzzers on right and left sides, and has turning and stop signal led matrices. Tools/Programming Languages used: Rhino 3D, 3D printer, Arduino, C.
				</br><br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/kevin-shum.png" alt="Kevin Shum" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Kevin Shum (UROP):</b> Kevin also hopped onto the project to help with last minute example building. Kevin built a pair of interactive CurveBoard headphones that is capable of receiving radio and music playing, with sound frequency visualization on a led matrix. Tools/Programming Languages used: Rhino 3D, 3D printer, Arduino, C.
				</br><br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/jessica-quaye.jpg" alt="Jessica Quaye" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Jessica Quaye (UROP):</b> Finally, Jessica helped with example by building the circuit on CurveBoard trinity bracelet and Utah Teapot models shortly before the deadline. Tools/Programming Languages used: Rhino 3D, 3D printer, Arduino, C.
				</br><br></br><br>
			</div>
		</div>


		<div class="col-md-2" style="text-align: left;">
			<a href="research/gid/gid.html"><img src="research/gid/gid-thumbnail.png" width="110px"></a>
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				<a href="research/gid/gid.html">G-ID (ACM CHI 2020 Paper)</a>
			</div>
			This project was led by HCIE <a href="http://www.dogadogan.com/">PhD student Doga Dogan.</a><br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/andrew-churchill.jpg" alt="Andrew Churchill" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Andrew Churchill (UROP):</b>

				I started by researching, designing, and iterating on a computer vision algorithm to detect the shape of a 3D printed object’s internal structure. This meant several tries at finding the right algorithm, as well as lots of learning about how to clean up noisy images to get something the algorithm could even work on in the first place. Then, once I had a working Python prototype for the algorithm, I rewrote it in C++, and wrote an Android app which used that C++ code on images from the phone’s camera to detect the internal structure. I also incorporated another computer vision algorithm written by Doga, which was based on 2D Fourier transforms.

				<br> Tools/Programming Languages used: Python, OpenCV, C++, Android, Java
				<br><br>
			</div>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/leon-cheng.jpg" alt="Leon Cheng" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Leon Cheng (UROP):</b>
				I developed a coffee machine prototype with custom electronics to illustrate the capabilities of individually identifiable 3D printed mugs. I built this by disassembling a standard coffee machine and then modifying and reconstructing it, using 3D modeling and printing to build a mug stand and a LCD screen to form an interactive electronic coffee dispenser.<br>
				Tools/Programming Languages used: Languages used: Arduino, Rhino, Grasshopper.

				</br><br>
			</div>
		</div>
		    <div class="col-md-2" style="text-align: left;">
			<a href="research/photochromeleon/photochromeleon.html"><img src="research/photochromeleon/images/reprogramming%20new%20textures.png" width="110px"></a>
		</div>
		<div class="col-md-10" style="text-align: left;">
			<div class="medium-headline" style="padding-bottom:10px">
				<a href="research/gid/gid.html">Photo-Chromeleon (ACM UIST 2019 Paper, Best Paper Award)</a>
			</div>
			This project was led by HCIE Postdocs <a href="http://ultra-jin.com/" target="_blank">Yuhua Jin</a>, <a href="https://www.isabelqamar.co.uk/" target="_blank">Isabel Qamar</a>, and <a href="http://michaelwessely.com/" target="_blank">Michael Wessely</a>.<br><br>
			<div class="col-md-15" style="text-align: left;">
				<img src="images/people/aradhana-adhikari.jpg" alt="Aradhana Adhikari" class="img-urop img-rounded">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<b>Aradhana Adhikari (UROP):</b>

				I developed an automated evaluation system for the Photo-Chromeleon project. I wrote a program that controlled light sources, a camera system and an openCV image processing system that captured the behavior of photochromic coatings under varying illuminations with visible and ultraviolet light. The system also generated a plot of the captured data using a Matlab library.
				<br> Tools/Programming Languages used: Python, OpenCV, Java
                <br><span style="background:orange">Morais &amp; Rosenblum Best UROP Award</span>
				<br><br>
			</div>

		</div>
		


<br>




<!--
<h4>10) AR Games for Learning Prototyping Skills (with Dishita)</h4><br>
<b>Topic:</b> AR games have been proven to provide better learning experience for various skills in classrooms. In this project, we develop AR based game interface to teach novices prototyping skills such as laser-cutting, 3D printing, breadboarding and other basic maker-skills. As the learner plays a game, various personalized props get released during the game-play that are designed to improve the learner's prototyping skills. At the end of the project, we expect to run a user-study to assess the learning gain of learners.  <br>
<b>Your job:</b> As a UROP/MEng, you will be working on either hardware (for applications in other domains) or software (for seamless synchronization of sensors and actuators for amateurs). Skills for hardware side application: Rhino3D, prototyping with arduino, basic digital fabrication (lasercutting/3D printing), basic MechE building (using workshop tools, soldering circuits etc) and basic electronics (working with sensors/actuators etc). For Software side application: Unity3D, Vuforia, python, C# or VB Scripting, 3D Rhino, Grasshopper, Blender etc. Interest in games and having worked with Hololens or any other AR/VR device is a plus.  -->



<!-- 		<div class="col-md-2" style="text-align: left;">
				<img src="images/publications/foldtronics/foldtronics.jpg" width="110px">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<span class="publication-authors">
				Junichi Yamaoka, Mustafa Doga Dogan, Katarina Bulovic, Kazuya Saito, Yoshihiro Kawahara, Yasuaki Kakehi, Stefanie Mueller.
				</span>
				</br>
				<span class="publication-title" style="font-weight:bold;">
				FoldTronics: Creating 3D Objects with Integrated Electronics Using Foldable Honeycomb Structures.
				</span>
				</br>
				<span class="publication-proceedings">
				In <i>Proceedings of CHI 2019 (to appear)</i>.
				</span>
				</br>
			</br>
			</div>



			<div class="col-md-2" style="text-align: left;">
				<img src="images/publications/craftsupport/craftsupport.jpg" width="110px">
			</div>
			<div class="col-md-10" style="text-align: left;">
				<span class="publication-authors">
				Martin Nisser, Junyi Zhu, Tianye Chen, Katarina Bulovic, Parinya Punpongsanon, Stefanie Mueller.
				</span>
				</br>
				<span class="publication-title" style="font-weight:bold;">
				Sequential Support: 3D Printing Dissolvable Support Material for Time-Dependent Mechanisms.
				</span>
				</br>
				<span class="publication-proceedings">
				In <i>Proceedings of TEI 2019 (to appear)</i>.
				</span>
				</br>
				<a href="research/sequential-support/sequential-support.html" class="btn btn-homepage" alt="page">Project Page</a>
				</br>
			</br>
			</div>



 -->



	</div>

		<div class="col-md-4" style="text-align: left;">
			<h3 class="headline">Previous UROPs/MEng-es</h3>

			<hr>

			<h3 class="medium-headline">
				<a href="https://yunyi-zhu.github.io/">Yunyi Zhu (6-3, UROP/SuperUROP/MEng/ongoing PhD)</a>
			</h3>

			<div class="col-md-12" style="text-align: left;padding-bottom:30px">
				<img src="images/uropmeng/yunyi-zhu-demo.jpg" width="250px" alt="Xin Wen" >
			<p style="text-align:center; margin-top:0px">
				<ul style="padding-left:0px;">
					<li><a href="https://hcie.csail.mit.edu/research/curveboard/curveboard.html">implemented 3D modeling plugin for research project CurveBoards + co-authored ACM CHI 2020 paper</a></li>
					<!-- <li>presented ColorMod at ACM CHI conference in Montreal as talk and live demo (3000 attendees)</li> -->
					<!-- <li><a href="https://www.csail.mit.edu/news/changing-color-3-d-printed-objects">ColorMod mentioning Xin covered by BBC, CNN, and was a main spotlight on MIT website</a></li> -->
					<li><a href="https://www.eecs.mit.edu/best-best-superurop-2018-2019-award-winners/">MIT EECS Best SuperUROP Award for her work on CurveBoards</a></li>
					<li><a href="https://hcie.csail.mit.edu/research/morphsensor/morphsensor.html">continued to work on the user interface for research project MorphSensor + co-authored ACM UIST 2020 paper</a></li>
					<li><a href="https://hcie.csail.mit.edu/research/lenticularobject/lenticular-object.html">implemented the software and hardware pipeline for research project Lenticular Objects + co-authored ACM UIST 2021 paper</a></li>
					<li>presented Lenticular Objects at ACM UIST conference as talk and live demo (565 attendees)</li>
					<li><a href="https://www.eecs.mit.edu/2021-eecs-awards/">MIT EECS Licklider Best UROP Award for her work on Lenticular Objects</a></li>
					<li>Works by Yunyi have been covered by <a href="https://www.csail.mit.edu/news/electronic-design-tool-morphs-interactive-objects">MIT News</a> and <a href="https://www.csail.mit.edu/news/changing-color-3-d-printed-objects">MIT EECS News</a> and <a href="https://cacm.acm.org/news/243352-integrating-electronics-onto-physical-prototypes/">ACM TechNews</a></li>
					<li>path in the lab: SuperUROP fall 2018/spring 2019, UROP fall 2019, MEng spring 2020/fall 2020/spring 2021, ongoing PhD since fall 2021</li>
				</ul>
				<img src="images/uropmeng/yunyi-zhu-poster.jpg" width="350px" alt="Xin Wen" >
				<img src="images/uropmeng/yunyi-zhu-chi.jpeg" width="350px" alt="Xin Wen" >

			</p>
			</div>

			<hr>

			<h3 class="medium-headline">
				Ahmad Taka (6-2, UROP, SuperUROP)
			</h3>

			<div class="col-md-12" style="text-align: left;">
				<img src="images/uropmeng/ahmad-taka.jpg" width="350px" alt="Xin Wen" >
			<p style="text-align:center; margin-top:0px">
				<ul style="padding-left:0px;">
					<li>developed a communication system between tiny robots and a 3D printer with PhD student Martin Nisser, which resulted in a first-author paper called <a href="https://dl.acm.org/doi/10.1145/3623509.3633365">FabRobotics</a> at ACM TEI'24</li>
					<li>implemented a fluorescent marker tracking system while working with PhD student Mustafa Doga Dogan, which resulted in a full paper called <a href="https://hcie.csail.mit.edu/research/brightmarker/brightmarker.html">BrightMarker</a> at ACM UIST'23</li>
					<li>implemented SVG embedding plugin while working with PhD student Mustafa Doga Dogan, which led in a full paper called <a href="https://hcie.csail.mit.edu/research/infraredtags/infraredtags.html">InfraredTags</a> at ACM CHI'22, also presented the project as a live demo at the conference in New Orleans</li>
					<li>received MIT EECS Best UROP Award 2022</li>
				</ul>

			</p>
			</div>





			for a list of <a href="https://hcie.csail.mit.edu/people.html">all previous MEng-es and UROPs, please see the team subpage</a>.
<!--

			<div style="margin-bottom:35px">

					<h4 style="font-weight:normal; margin-bottom:10px;"><a href="https://risingstars18-eecs.mit.edu/" target="_blank">MIT EECS Rising Stars Workshop 2018</br></a></h4>
					<a href="https://risingstars18-eecs.mit.edu/" target="_blank"><img src="images/logo/risingstars.jpg" height="170px"></a>
			</div> -->




<!-- 		We are also part of MIT's International Design Center <br><br>
		<a href="http://idc.mit.edu/">
		<img src="images/logo/IDC.jpg" alt="International Design Center" width="200px">
		</a><br><br> -->
	</div>
	</div>


		<!-- News list: end section -->
	</div>
</div>

<div class="dc_clear">
</div>

</br>
</br>
</br>
</br>
</section>

<div class="container">
	<div class="row">
		<div class="col-md-12 footer" style="text-align: center;">
			<span class="copyright">
			Since 2017 &copy; MIT CSAIL (HCI Engineering group) [redesign by
			<a href="http://punpongsanon.info/" target="_blank" style="text-decoration:none; border-bottom:0px">
			moji
			</a>].
			All Rights Reserved.

			<a href="http://mit.edu/" target="_blank" style="text-decoration:none; border-bottom:0px">
			<img src="images/logo/mit.svg" alt="MIT" class="footer-logo" />
			</a>
			<a href="http://csail.mit.edu/" target="_blank" style="text-decoration:none; border-bottom:0px">
			<img src="images/logo/csail.svg" alt="CSAIL" class="footer-logo"/>
			</a>
			<a href="http://hci.csail.mit.edu/" target="_blank" style="text-decoration:none; border-bottom:0px">
			<img src="images/logo/hci.svg" alt="HCI" class="footer-logo"/>
			</a>
			</span>
		</div>
	</div>
</div>

<!-- Bootstrap -->
<script type="text/javascript" src="js/bootstrap.min.js"></script>
<!-- header -->
<script type="text/javascript" src="js/headerstrap.js"></script>
<!-- footer -->
<script type="text/javascript" src="js/footerstrap.js"></script>

</body>
</html>
